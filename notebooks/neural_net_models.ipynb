{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network models\n",
    "\n",
    "This notebook picks up after the `simple_models` notebook. After trying a range of classification algorithms, we'll try out some of the neural network models in [1]. These include fully-connected models of varying layer sizes, and finally convolutional models including the famous LeNet-5. \n",
    "\n",
    "Along the way, we'll be using Keras which is a library sitting on top of Theano or Tensorflow. This allows easy construction, training and evaluation of neural nets. Before we get started, here's a recap of the `simple_models` notebook models.\n",
    "\n",
    "`[1]` - [Gradient-Based Learning Applied to Document Recognition](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf),  LeCun et al, Nov 1998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "# plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = 'Helvetica'\n",
    "plt.rcParams['font.monospace'] = 'Consolas'\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['axes.labelsize'] = 16\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['xtick.labelsize'] = 14\n",
    "plt.rcParams['ytick.labelsize'] = 14\n",
    "plt.rcParams['legend.fontsize'] = 16\n",
    "plt.rcParams['axes.titlesize'] = 20\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# for auto-reloading external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pickle files\n",
    "\n",
    "The original data files are processed using the `convert_data.py` script, and written out to pickle files. We can load these in as numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pickle files\n"
     ]
    }
   ],
   "source": [
    "# Set up the file directory and names\n",
    "DIR = '../input/'\n",
    "X_TRAIN = DIR + 'train-images-idx3-ubyte.pkl'\n",
    "Y_TRAIN = DIR + 'train-labels-idx1-ubyte.pkl'\n",
    "X_TEST = DIR + 't10k-images-idx3-ubyte.pkl'\n",
    "Y_TEST = DIR + 't10k-labels-idx1-ubyte.pkl'\n",
    "\n",
    "def load_data():\n",
    "    '''Loads pickled ubyte files with MNIST data\n",
    "    INPUT: X_train_file, y_train_file - strings with training filenames\n",
    "           X_test_file, y_test_File - strings with test filenames\n",
    "    RETURNS: Tuple with (X_train, y_train, X_test, y_test)\n",
    "    '''\n",
    "    print('Loading pickle files')\n",
    "    try:\n",
    "        X_train = pickle.load( open( X_TRAIN, \"rb\" ) )\n",
    "        y_train = pickle.load( open( Y_TRAIN, \"rb\" ) )\n",
    "        X_test = pickle.load( open( X_TEST, \"rb\" ) )\n",
    "        y_test = pickle.load( open( Y_TEST, \"rb\" ) )\n",
    "    except:\n",
    "        print('Error loading pickle file')\n",
    "        return None\n",
    "    \n",
    "    return (X_train, y_train, X_test, y_test)\n",
    "\n",
    "X_train, y_train, X_test,  y_test = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "\n",
    "Before evaluating some models on the images, let's create some helper functions we can re-use later on. These deal with converting images to and from 1d and 2d versions, plotting images, resizing them, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train images shape (60000, 784), labels shape (60000, 1)\n",
      "Loaded test images shape (10000, 784), labels shape (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "def flatten_images(X):\n",
    "    ''' Converts images to 1-d vectors\n",
    "    INPUT: X - Input array of shape [n, w, h]\n",
    "    RETURNS: Numpy array of shape [n, w*h]\n",
    "    '''\n",
    "    n, w, h = X.shape\n",
    "    X_flat = X.reshape((n, w * h))\n",
    "    return X_flat\n",
    "\n",
    "def square_images(X, w=None, h=None):\n",
    "    '''Converts single-vector images into square images \n",
    "    INPUT: X - numpy array of images in single-vector form\n",
    "           w - width of images to convert to\n",
    "           h - height of images to convert to\n",
    "    RETURNS: Numpy array of shape [n, w, h]\n",
    "    '''\n",
    "    \n",
    "    assert X.shape[1] == w * h, \"Error - Can't square array of shape {} to {}\".format(X.shape, (w, h))\n",
    "    n = X.shape[0]\n",
    "    X_square = X.reshape((n, w, h))\n",
    "    return X_square\n",
    "\n",
    "\n",
    "N_TRAIN, W, H = X_train.shape\n",
    "N_TEST, w_test, h_test = X_test.shape\n",
    "\n",
    "# Flatten the images\n",
    "X_train = flatten_images(X_train)\n",
    "X_test = flatten_images(X_test)\n",
    "\n",
    "# Do some checks on the data\n",
    "assert N_TRAIN == 60000, 'Error - expected 60000 training images, got {}'.format(N_TRAIN)\n",
    "assert N_TEST == 10000, 'Error - expected 60000 training images, got {}'.format(N_TEST)\n",
    "assert W == w_test, 'Error - width mismatch. Train {}, Test {}'.format(w, w_test)\n",
    "assert H == h_test, 'Error - height mismatch. Train {}, Test {}'.format(h, h_test)\n",
    "\n",
    "assert np.array_equal(X_train, flatten_images(square_images(X_train, W, H)))\n",
    "assert X_train.shape[0] == y_train.shape[0]\n",
    "assert X_test.shape[0] == y_test.shape[0]\n",
    "\n",
    "print('Loaded train images shape {}, labels shape {}'.format(X_train.shape, y_train.shape))\n",
    "print('Loaded test images shape {}, labels shape {}'.format(X_test.shape, y_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "This section sets up global constants used in all models (to ensure a fair comparison). It also prepares the data by converting y values to one-hot, and normalizing X inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer, StandardScaler\n",
    "\n",
    "# Keras Common configuration\n",
    "SEED = 1234 # Fix the seed for repeatability\n",
    "N_JOBS=-2 # Leave 1 core free for UI updates\n",
    "VERBOSE=2 # 3 is the most verbose level\n",
    "EPOCHS = 20 # todo ! Check how many epochs in the paper\n",
    "BATCH = 256 # todo ! Check this in the paper too\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Useful helper functions\n",
    "def stratified_subsample(X, y, num_rows, verbose=False):\n",
    "    '''Creates a stratified subsample of X and y\n",
    "    INPUT: X and y, numpy arrays\n",
    "    RETURNS: subset of X and y, maintaining class balances\n",
    "    '''\n",
    "    # Create a stratified, shuffled subset of the training data if needed\n",
    "    N = X.shape[0]\n",
    "    \n",
    "    new_X, new_y = X, y\n",
    "    if num_rows < N:\n",
    "        if verbose:\n",
    "            print('Reducing size from {} to {} examples'.format(N, num_rows))\n",
    "        new_X, _, new_y, _ = train_test_split(X_train, y_train, # Undersample by dropping \"test\" data\n",
    "                                              train_size=num_rows, random_state=SEED)    \n",
    "    return new_X, new_y\n",
    "        \n",
    "def onehot_encode_y(y_train, y_test):\n",
    "    '''Convert y_train and y_test to a one-hot encoding version\n",
    "    INPUT: y_train - np.array of size (n_train,)\n",
    "           y_test - np.array of size (n_test,)\n",
    "    RETURNS: y_train - np.array of size (n_train, n_classes)\n",
    "             y_test - np.arary of size (n_test, n_classes)\n",
    "    '''    \n",
    "    print('Converting y variables to one-hot encoding..')\n",
    "    lbe = LabelBinarizer()\n",
    "    lbe.fit(y_train)\n",
    "    y_train = lbe.transform(y_train)\n",
    "    y_test = lbe.transform(y_test)\n",
    "    return y_train, y_test\n",
    "\n",
    "def z_norm_X(X_train, X_test):\n",
    "    '''Z-normalizes X_train and X_test with 0 mean and 1 std. dev.\n",
    "    INPUT: X_train - training set\n",
    "           X_test - test set\n",
    "    RETURNS: X_train - normalized version of same size\n",
    "             X_test - normalized version (using X_train parameters)\n",
    "    '''\n",
    "    print('Z-normalizing X data..')    \n",
    "    std = StandardScaler()\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_test = X_test.astype(np.float32)\n",
    "    std.fit(X_train)\n",
    "    X_train = std.transform(X_train)\n",
    "    X_test = std.transform(X_test)\n",
    "    return X_train, X_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting y variables to one-hot encoding..\n",
      "Z-normalizing X data..\n",
      "Train images shape (60000, 784), labels shape (60000, 10)\n",
      "Test images shape (10000, 784), labels shape (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "y_train, y_test = onehot_encode_y(y_train, y_test)\n",
    "X_train, X_test = z_norm_X(X_train, X_test)\n",
    "scores = dict()\n",
    "\n",
    "print('Train images shape {}, labels shape {}'.format(X_train.shape, y_train.shape))\n",
    "print('Test images shape {}, labels shape {}'.format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] C.5 - Baseline fully-connected models (original dataset)\n",
    "\n",
    "We'll first compare the performance of different fully-connected models on fully-connected networks of varying layers and size. These are all trained on the 28x28 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 1070 (CNMeM is disabled, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Create a dictionary to store model training and test info\n",
    "models = dict()\n",
    "\n",
    "class KerasFCModel(object):\n",
    "    \n",
    "    def __init__(self, model_name, model_type, input_dim, layers, \n",
    "                 activation, output_activation, verbose=2):\n",
    "        '''Initializes a new keras model'''\n",
    "        self.model_name = model_name\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        model = model_type\n",
    "        for idx, size in enumerate(layers):\n",
    "            \n",
    "            # First layer has to take input from image files\n",
    "            if idx == 0:\n",
    "                if self.verbose == 2:\n",
    "                    print('Adding input dense layer, input dim {}, dim {}'.format(input_dim, size))\n",
    "                model.add(Dense(size, input_dim=input_dim))\n",
    "                model.add(Activation(activation))\n",
    "                \n",
    "            # Last layer has to include the output activation\n",
    "            elif idx == len(layers) - 1:\n",
    "                if self.verbose == 2:\n",
    "                    print('Adding dense layer {}, size {}, activation {}'.format(idx, size, activation))\n",
    "                model.add(Dense(size))\n",
    "                model.add(Activation(output_activation))\n",
    "                \n",
    "            # Layers other than first and last have standard activation\n",
    "            else: \n",
    "                if self.verbose == 2:\n",
    "                    print('Adding output layer {}, size {}, activation {}'.format(idx, size, output_activation))\n",
    "                model.add(Dense(size))\n",
    "                model.add(Activation(activation))\n",
    "                \n",
    "        if self.verbose > 0:\n",
    "            print('Model summary:\\n')\n",
    "            model.summary()\n",
    "        \n",
    "        self.model = model\n",
    "        \n",
    "    def compile_model(self, loss, optimizer, metrics):\n",
    "        '''Compile the model'''\n",
    "        self.metrics = metrics\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer\n",
    "        # Need to flip error vs accuracy \n",
    "        metrics = ['acc' if metric is 'error' else metric for metric in metrics]\n",
    "        self.model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "          \n",
    "    def fit(self, X, y, epochs, batch_size):\n",
    "        '''Fit model to training data'''\n",
    "        self.history = self.model.fit(X, y, epochs=epochs, batch_size=batch_size, verbose=self.verbose)\n",
    "\n",
    "    def evaluate(self, X, y, batch_size):\n",
    "        '''Evaluates the model on test data'''\n",
    "        output = self.model.evaluate(X, y, batch_size=batch_size)\n",
    "        results = dict()\n",
    "        for idx, metric in enumerate(self.model.metrics_names):\n",
    "            if metric == 'acc':\n",
    "                results['error'] = 1.0 - output[idx]\n",
    "            else:\n",
    "                results[metric] = output[idx]                \n",
    "        self.results = results\n",
    "    \n",
    "    def report(self):\n",
    "        '''Prints a recap of the model, how it was trained, and performance'''\n",
    "        report = dict()\n",
    "        if self.verbose > 0:\n",
    "            report['model_info'] = self.model.summary()\n",
    "            report['loss'] = self.loss\n",
    "            report['optimizer'] = self.optimizer.get_config()\n",
    "            report['metrics'] = self.metrics\n",
    "            report['history'] = self.history\n",
    "        report['results'] = self.results\n",
    "        return report\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function to evaluate fully-connected models\n",
    "def evaluate_fc_model(name, layers, activation, optimizer,\n",
    "                            X_tr, y_tr, X_te, y_te,\n",
    "                            epochs, batch_size,\n",
    "                            verbose=2):\n",
    "    \"\"\"Creates, trains, and evaluates neural network on provided data\"\"\"\n",
    "    \n",
    "    print('Creating Keras model {}'.format(name))\n",
    "    model = KerasFCModel(model_name=name, model_type=Sequential(), \n",
    "                           input_dim=784, layers=layers, \n",
    "                           activation=activation, output_activation='softmax',\n",
    "                           verbose=verbose)\n",
    "\n",
    "    print('Compiling model')\n",
    "    model.compile_model(loss='categorical_crossentropy',\n",
    "                        optimizer=optimizer,\n",
    "                        metrics=['error'])\n",
    "\n",
    "    print('Training model')\n",
    "    model.fit(X_tr, y_tr, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    print('Evaluating model')\n",
    "    model.evaluate(X_te, y_te, batch_size=batch_size)\n",
    "\n",
    "    print('\\nTest results: {:.2f}% error'.format(100.0 * model.report()['results']['error']))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully connected single-hidden layer networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Keras model fc-300-10\n",
      "Compiling model\n",
      "Training model\n",
      "Evaluating model\n",
      " 5632/10000 [===============>..............] - ETA: 0s\n",
      "Test results: 2.85% error\n",
      "CPU times: user 13.2 s, sys: 2.84 s, total: 16 s\n",
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "fc_results = dict()\n",
    "fc_results['fc-300-10'] = evaluate_fc_model('fc-300-10', layers=(300,10), activation='tanh', \n",
    "                                            optimizer=SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True),\n",
    "                                            X_tr=X_train, y_tr=y_train, X_te=X_test, y_te=y_test,\n",
    "                                            epochs=EPOCHS, batch_size=BATCH,\n",
    "                                            verbose=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Keras model fc-1000-10\n",
      "Compiling model\n",
      "Training model\n",
      "Evaluating model\n",
      " 8448/10000 [========================>.....] - ETA: 0s\n",
      "Test results: 2.55% error\n",
      "CPU times: user 13.8 s, sys: 5.1 s, total: 18.9 s\n",
      "Wall time: 18.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# FC 1000-10\n",
    "fc_results['fc-1000-10'] = evaluate_fc_model('fc-1000-10', layers=(1000,10), activation='tanh', \n",
    "                                            optimizer=SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True),\n",
    "                                            X_tr=X_train, y_tr=y_train, X_te=X_test, y_te=y_test,\n",
    "                                            epochs=EPOCHS, batch_size=BATCH,\n",
    "                                            verbose=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two hidden layer fully connected networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Keras model fc-300-100-10\n",
      "Compiling model\n",
      "Training model\n",
      "Evaluating model\n",
      " 8704/10000 [=========================>....] - ETA: 0s\n",
      "Test results: 2.56% error\n",
      "CPU times: user 13.5 s, sys: 352 ms, total: 13.8 s\n",
      "Wall time: 13.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# FC 300-100-10\n",
    "fc_results['fc-300-100-10'] = evaluate_fc_model('fc-300-100-10', layers=(300,100,10), activation='tanh', \n",
    "                                            optimizer=SGD(lr=0.1, decay=1e-5, momentum=0.9, nesterov=True),\n",
    "                                            X_tr=X_train, y_tr=y_train, X_te=X_test, y_te=y_test,\n",
    "                                            epochs=EPOCHS, batch_size=BATCH,\n",
    "                                            verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Keras model fc-500-150-10\n",
      "Compiling model\n",
      "Training model\n",
      "Evaluating model\n",
      " 7168/10000 [====================>.........] - ETA: 0s\n",
      "Test results: 2.70% error\n",
      "CPU times: user 14.1 s, sys: 2.58 s, total: 16.7 s\n",
      "Wall time: 16.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# FC 500-150-10\n",
    "fc_results['fc-500-150-10'] = evaluate_fc_model('fc-500-150-10', layers=(500,150,10), activation='tanh', \n",
    "                                            optimizer=SGD(lr=0.1, decay=1e-5, momentum=0.9, nesterov=True),\n",
    "                                            X_tr=X_train, y_tr=y_train, X_te=X_test, y_te=y_test,\n",
    "                                            epochs=EPOCHS, batch_size=BATCH,\n",
    "                                            verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fc-1000-10</th>\n",
       "      <td>2.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fc-300-100-10</th>\n",
       "      <td>2.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fc-500-150-10</th>\n",
       "      <td>2.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fc-300-10</th>\n",
       "      <td>2.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               error\n",
       "fc-1000-10      2.55\n",
       "fc-300-100-10   2.56\n",
       "fc-500-150-10   2.70\n",
       "fc-300-10       2.85"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the FC results so far into a dataframe for easy plotting\n",
    "\n",
    "fc_scores = {result: value.results['error'] for result, value in fc_results.items()}\n",
    "fc_scores_df = pd.DataFrame.from_dict(fc_scores, orient='index')\n",
    "\n",
    "fc_scores_df.columns = ['error']\n",
    "fc_scores_df['error'] *= 100.0\n",
    "fc_scores_df = fc_scores_df.sort_values('error', ascending=True)\n",
    "fc_scores_df.to_pickle('fc_scores.pkl')\n",
    "fc_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAGRCAYAAABrD7qUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe986a8df98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "fc_scores_df.plot.barh(width=0.4, ax=ax, legend=None)\n",
    "ax.set(title=\"Fully-connected neural net test-set accuracy\", ylabel=\"Network\", xlabel=\"%age error\");\n",
    "plt.savefig('fc_scores.png', bbox_inches='tight', dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural networks\n",
    "\n",
    "Now let's see how much further we can improve performance with convolutional neural networks. For the convolutional networks, we need a 2-d image instead of the flattened 1-d vector the fully connected networks used. We also need to add padding around each of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pickle files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load image pickle files\n",
    "X_train, y_train, X_test,  y_test = load_data()\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAC8CAYAAABMmhi7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n46tOSsAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe96013c390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot a few random numbers to sanity check their size and that they look correct\n",
    "N = 3\n",
    "indexes = np.random.choice(X_train.shape[0], N)\n",
    "fig, ax = plt.subplots(1, N)\n",
    "\n",
    "for num, idx in enumerate(indexes):\n",
    "    ax[num].imshow(X_train[idx])\n",
    "    ax[num].set(title=\"Label={}\\n{}x{}\".format(y_train[idx], *X_train[idx].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Padding images to 32x32 while centering image\n",
    "\n",
    "In [1], the images are padded to 32x32 to ensure every pixel of the input image ends up in the center of the receptive fields of the highest level feature receptors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_border(image, size, fill):\n",
    "    \"\"\"\n",
    "    Adds a border around the nupmy array of the gizen size and value\n",
    "    \"\"\"\n",
    "    im_w, im_h = image.shape\n",
    "    im_dtype = image.dtype\n",
    "    \n",
    "    new_image = np.full((im_w + (2 * size), im_h + (2 * size)),\n",
    "                        fill_value=fill, dtype=im_dtype)\n",
    "    new_image[size:im_h + size, size:im_w + size] = image\n",
    "    \n",
    "    assert new_image.dtype == image.dtype\n",
    "    assert new_image.shape[0] == image.shape[0] + (2 * size)\n",
    "    assert new_image.shape[1] == image.shape[1] + (2 * size)\n",
    "    assert np.array_equal(image, new_image[size:size+im_h, size:size+im_w])\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnkAAAGoCAYAAAA6g/O2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3XmYFOXV9/Evsgi44IKoURRjyMH1FR3BLaAhxi0u+Cgx\nRA1x99VE0Bj1wUSNJkJwAdQISlAUV9Qk4pLgq6iJCskoYkQ5D+qjokTFSMYYXGHeP6obu5aZ7pnp\nnq6u+X2ui6v7vqu66vRQZ+bu6nvp1NjYiIiIiIhky1rVDkBEREREyk+NPBEREZEMUiNPREREJIPU\nyBMRERHJIDXyRERERDJIjTwRERGRDOpS7QBqmZntC8wFLnH3i8t87EbgCXfft5WvfxwYWlB1kLv/\nscTXngZcX1A1w91HtSYOkfaW4bw8EHi4oKrVcYhUQ4ZzcxxwXkFV2d9fa3WYRp6ZjQJuAi5w93FV\nDqc9HZ17XABgZh8B6zSx77vuvhkwJ/e6TYDfVDxC6bCUl0FeRpnZAGAh0M3dOxXsm3/drMqGJx2d\ncnPN38y1gXOB7wHbAiuBJ4D/dveXc/vOBOqBHYCL2zPYYjpMI6+jcvd78s/NrAtBA+8Z4KqE3T/J\nveY14DUz69ceMYp0NIV5GWVmnYAbgW6R17wL3JPbp6LxiXRUkb+ZnYGHgG8CfwImAesS3LV7xsz2\ncPfF7v4i8KKZvV+NmJujRl7HskHu8eXm/siISFWdCuwNPA/sUuVYRDqyEQQNvD8Aw929EcDMHiS4\n034VcHD1witOjbwEFnxMvgD4NsFXlssJbt1e7O5/a+I13wEuIrhd+wlB35lz3P2dyH6HA2cDuxL8\n/P8XuAOY4O6fNBPT+hQfKLPa3T9sZnu+kddQ5DgiqZPhvCw83leAcQRf/6xGjTypARnOzYNyj5Pz\nDTwAd3czuwf4npn1cff3ipynajS6NsLMtgD+AhwGXAv8AJgI7Aw8ZWZ1CS/bg6Dv2mzgTOD3wEjg\nITNb8zM2sx/ltjUSfMd/JkEiXALcn/uapikvACuK/HuhyNvLN/L+lYuns5n1KPIakarLeF4WuhZY\nBZzTgteIVE3Gc3Pz3ONrCdueJ2hD7VbkGFWlO3lxOxD8x09z9zvylWa2EPgjcBpwUuQ13wR2cnfP\nlaebWVfgWIJPAg+a2abAr4EHgUMLPhX81sz+QfBL/Qjgd03EdQzQvUjsTX6qyck38nYysz8DewKd\nc+e/lWBE0MoixxCphiznZf69DAeGAye6+3L1u5MakeXczH/rtQnwemTbx7nHrYsco6rUyItw9zkE\no0sBMLN1gK7Am7mqfgkve6LgYs27m+CC3Y/gIj2M4IK7E+gV+QV+H8EFuy9NXLDuPq9l7yRRvpF3\nCMEnrsuB3rk4fwrsbWb7uvsXZTiXSNlkPC/zXy1dCzxJMKJRpCZkPDf/DPwXcBSw5mvn3N3GEbni\numU4T8WokZcg94n6R8Ag4tONJP3MXkyoy9/ezbfyt8893trMqbcqNcZWeprgU9Ir7v5KQf0tZnYf\nwV2EkcAtFY5DpMUynJcQ3LHoDQwr7PsjUgsynJtTCfoDjjGz5QSNy/WB8wvO/WmFY2gTNfIizOxE\nYBqwlGC+m5cI5sXZCLi3iZf9O6Eufys33+dtvdzjGILv8pOsaCauDYHOTW3PWeXuTR7D3ZcBy5rY\nfC1BI29/1MiTlMlyXprZPsApwKXuvrjIsURSJcu56e6fmNkw4HZgQu7faoL3dQHBAJAPipyjqtTI\ni/sJQcfnb7n7/+QrrfkOMj2bqcv3cctf1Mvc/fFWxLWA4t/9v0HyrfFSvJt7XL+VrxeppEzmpZl1\nI5gT73VghpltGY01X+fub7UiPpFKy2Ru5uW+9RpkZl8naLi+musz+6PcLi83/erqUyMvbhvgzcKL\nNWdIM6/ZLqHua7nH/C3oRbnHvQn6HqyR+0XfvchQ7jZ3IjWzvQmmZLjZ3f8T3Zx7fBOR9MlqXn4F\nGJB7/moT+yzNPTY3klCkWrKamyEJ7+8ggqliFpZ6jGpQIy/uXaCPmfXMjzQ1s74E/Q3gy1vJhYaZ\n2bbuXvhLemTu8dHc4/0EX4kea2a/jMyrMxr4hZl9292fTAqqTJ1Ivw38nOA9XJGvzI1qOjdXvK8M\n5xEpt6zm5bvAoU1sGw0Ma2a7SBpkNTfzN0buAaa7+9iC+iHAgcCv3H1VW89TSR2xkbejmR3VxLbn\ngbsIGjz3mtntwBbAjwkuqquBXczsNILRP3lPEMwHdA1Bn7eDCNa/ewb4fwDu/p6ZnUcwf9DTZjaZ\nYHj2EGAUwSiep8v4PpNcTTAiaLyZbUcwt1Ev4HhgIDDV3edWOAaRJB0yL939Y+CBpG35n4e7J24X\naScdMjdz5gHvAOeb2XrAfII77/l+gqlf07cjNvK+n/uXZAxBx9HuwJHA9QSjgE5z9/vNbF2CO2CX\nE3QuzXsYuI5g9u7tCfoU3EIwe3fhLNmTzOyN3Hkuy53n9dzxLq/01CXu/q/cJ5OfENzKPo5gZNAL\nwCh3n1HJ84s0o8PmpUjKddjcdPdVZrY/8EuCgYmnAv8AphDMK/tRJc9fDp0aGzVaP4vM7HFgqLu3\nuh+PmfUjWEJmhruPKk9kIh1XOfIyd5xGgrnG9i1HXCIdXZn+Zu4LzCVoAF5cnsjaRsuaiYiIiGRQ\nR/y6tkMp6EvxZ3d/t9mdv3zNVwkWg96kYoGJdGCtzMtNgW9ULioRaWVu7kjQV2+HigXWSmrkZd+s\n3ONBBOsIluLbBH0rRKQyWpOXAwteJyKV0ZrcPBY4rzLhtI365ImIiIhkkPrkiYiIiGSQGnkiIiIi\nGaRGnoiIiEgGaeBFEWa2CcFSYMMJRpu+DfwVuNjdF0f27QOMBY4gWJPyI+BZYJK7z27l+bsBZwIn\nE6wRuIJgUslfu/ufIvuuDfxf4CRgW4JFoxcDtwLXalJXyRLlpkj6KC/TRQMvmpG7AJ8FNiYYbboQ\n+DrBki1dgL3dfUFu3y1z+66f2/d5ggv8ZMCAM9z9Ny08/1oES8EcSLB0zJ+ADYEzgK8Cp7v7lIJ9\nnwD2IVjM+RGgK0HyfBuY5e4jWvNzEEkb5aZI+igv00eNvGaY2Q0EF9x/uft9BfWHA7+n4CIwsyuB\ns4FT3f2Ggn17A68BnwF93H11C84/ErgNuMbdf1xQ/xXgfwg+9Wzu7o1mdijBgs53uPvIyHGeBvYE\ndnH3hS35GYikkXJTJH2Ul+mjPnnNWwbcAfwuUv9HoBHYqaBu29zjnwt3dPf3gZcJPtmsZ2Z9zGy5\nmb1qZj0K9zWz88ys0cwuyFWtJviEcW3kmMsIPiFtCvRp7vyRun5NvE+RWqPcFEkf5WXKqE9eM5pZ\ne249oBPwTkHdYuBwglvTL+crzawzsCXwlrs35OrOBO4k6ItwYa6uL/Az4G/Ar3PnvzO3X5JewOfA\nBwXnJ3f+qH4ECbaoiWOJ1BTlpkj6KC/TR4281jkr9/j7grpJwEhgkpl9BtQT9AW4ANgMOC6/o7vf\nlVs65Vwzm5nrjDqZ4P/jB+6+qrmTm9kwguVTfu/un+eq/wTMAU4zs/8B/kBwp/a7wJHADe7+Shve\ns0gtUG6KpI/yskrUJ6+FzOw7BBfDAmAvd/+sYNvmBJ09C9eXbABOdvdZkeNsQvApYRFwBfAAcJ67\n/7rI+fsB84C1gTp3f7VgWzdgInB6wUtWA+OAC91d/9mSWcpNkfRRXlaX+uS1gJkdB9xH0Cn00MjF\nuhnBRbcTwS3lQ4BjCEYMzcy9dg13X04w4mdfgtvL84Ari5x/IPAMsC4wPHKxrgX8FjgFuA74L+Aw\n4GaCT0YtGqUkUkuUmyLpo7ysPn1dWyIz+xnwC4Jbyoe4+3uRXSYAuxJ8Unmm4HV3EwwTv97M/pi7\nUPPuB5YTDBuf2dwtZzM7iKBD6SfAMHefH9nlhwSLJP+3u19eUD/bzD4ERpvZbHd/qPR3LZJ+yk2R\n9FFepoPu5JXAzCYSXKz3A0MTLlYI5tX5R+HFCpC73fswsA4wKPKaXwC9CTqdXmJmmzZx/qOB2QQj\nlwYnXKz58wPcm7Atf5Hul3R8kVql3BRJH+VleqiRV0Tu08hZwE3Ake6+sold1wG6N7Gte+QRMxsE\nnANMJZgZfF1gSsL5hwEzCYZ/7+3urzVxjnWj52ju/CK1Trkpkj7Ky3RRI68ZZrYfcAnBnD8nFRnB\n8wywoZkdEDlGN4Jh4quA+bm6tQm+938PON/dHbgcOMLMvl/w2k0I5hx6CzggN39QU57OPR6TsO3o\nyD4iNU25KZI+ysv00ejaZpjZs8BAgnXwkm43Azzk7ivNrI5giRQIOmz+HegJnArsAlzu7v+dO+54\n4KfAUe5+b66uG8Enjz7ADu7+jn05I/h1wONNnP9v7v6GmW1AsD5gf+D23P6fESTLcILJHb/pGViL\nT0S5KZI+ysv0USOvGWZWyg9nG3d/Pbf/dgSjhPYjuPBWAi8A17v77bl9BhF8OnjQ3Q+PnG8IwYU2\n290PN7PHgaFFzv9Dd7859/oNgf8muEi3IpjM8RWCIepXuPsnJbwfkdRTboqkj/IyfdTIExEREckg\n9ckTERERySA18kREREQySI08ERERkQwqy4oXZtaXYDTLXsDHBOvUjSlYCDikoaFBHQGlJL169epU\n7RhqlfJSKkV52XotzUtQbkppkvKyXHfy7gM+AL4G7ENw8V5apmOLSOsoL0XSR3kp7abNo2tzc93M\nBzbNTzxoZkcBNwC93X119DX6VCKl0h2D1lFeSiUpL1unNXkJyk0pTVJeluPr2t2ApZGZpZ8DNgS2\nBZY09+IlS5ZQV1dXhjCqp76+vqbfQ9rib2hoqHYIWdCmvOzVq1fqrouWqvX4IV3vQXlZFm3KS9Df\nzDRIU/zF8rIcjbyNgRWRug9yj70p4aKtr68vQxjVVevvIU3x9+/fv9ohZEGb8jJ/PaTpumiNWo8f\n0vMelJdl0ea/l5Cea6Itav09pCX+YnlZloEXCfK3DEu6xZyWFnFrpalV3xppi193DCqm5Lysq6tL\n3XXRUrUeP6TrPSgvK6ZFfy9BfzOrLU3xF8vLcgy8WE7wCaTQRgXbRKT9KS9F0kd5Ke2qHI28emAL\nM9u8oG4QweLEr5Xh+CLScspLkfRRXkq7anMjz90XAPOA8WbWy8y+ClwIXOvuGhEkUgXKS5H0UV5K\neyvXPHlHAesDrwJzgQeBX5Xp2CLSOspLkfRRXkq7KcvAC3dfBhxRjmOJSHkoL0XSR3kp7Ulr14qI\niIhkkBp5IiIiIhmkRp6IiIhIBqmRJyIiIpJBauSJiIiIZJAaeSIiIiIZpEaeiIiISAapkSciIiKS\nQWrkiYiIiGRQWVa8EBEpxaeffhqrGzFiRKzu0ksvjdXtvPPOFYlJRCSrdCdPREREJIPUyBMRERHJ\nIDXyRERERDJIjTwRERGRDOrwAy+++OKLWN0dd9wRqxs1alSs7qyzzgJg5MiRnH322fTr1y+2z7PP\nPhurmzlzZkmxrV69Ola31lrxdvlxxx0XKid1Wu/bt29J5xSppKRr+pFHHonVHXXUUbE6DbwQEWkZ\n3ckTERERySA18kREREQySI08ERERkQxSI09EREQkgzrUwIukTt9jxoyJ1V1//fWxuk6dOsXqJk+e\nDAQDL/LPS5F0rCRJgyySXhsdyPHGG2/E9pk7d26J0YlUTo8ePWJ13/ve92J1d911V6wuaTBG0vFE\npHbNnz8/Vnf66afH6hYuXBir69OnT6zuxBNPLE9gwKmnnrrm+dKlS4H0D2rUnTwRERGRDFIjT0RE\nRCSD1MgTERERySA18kREREQyqEMNvFi+fHmsLmmQRTX07t07VpfUiXTVqlWxOnevSEwi7SGpY/Q3\nvvGNWN0FF1wQq5s4cWJFYiqHN998M1SeNWtWbJ9zzjmnvcIRSZ3Ro0fH6qZPnx6r+89//hOrSxqE\n+N5778Xqxo0bF6trbGwseqzoPgCLFi0CYOzYsfz4xz8GYOrUqbH9kv52V4vu5ImIiIhkkBp5IiIi\nIhmkRp6IiIhIBqmRJyIiIpJBmR148fnnn8fq9t9//1Yfb/vtt4/VjR07ds3z2267ja233rrVx+/X\nr1+sbrPNNovVffHFF7G6Rx55JFT++OOPWx2HSHvr1q1bSftdc801sbo0D7wYPHhwqJzUKVwDLySr\nGhoaYnU/+MEPALjwwgs54ogjuP/++2P7JA2C2GabbWJ1t99+e6xu0KBBrQk10RFHHBGry8c7duzY\nNc+TBk3+5je/idV17dq1bLG1hO7kiYiIiGSQGnkiIiIiGaRGnoiIiEgGqZEnIiIikkGZHXjRuXPn\nWN3uu+8eq3vppZdidUmDLObNmxer69mzJwD19fV897vfbU2YLdalS/y/7KCDDmqXc4u0l6TZ5mtN\n9D1k4T2JJEkaVFQ4MDHvgQceAIKBFw888EDiIIuTTjopVnf11VfH6vJ/fytlxowZsbpbbrllzfP8\noK/LL788tt/KlStjdb169SpjdKXTnTwRERGRDFIjT0RERCSD1MgTERERyaCS+uSZ2U7AHcC67t6v\noH4oMB7YHlgGTHT3KRWIU0QSKDdF0kd5KWlRtJFnZiOAq4G/AgML6jcDZgPnATfntj1sZq+7+x8r\nEm07Wbp0aaxu5MiRTe6fn727LYYMGRKrGzVqVKxuo402atN5JDuykps777xzrG7jjTeO1X3wwQft\nEU7ZRDuVJ3UyT1rBJmlwldSOrORlUz777LNYXdIgi2nTpsXq1lrryy8PGxsbefrpp2P7RFeKqZaH\nH344VtenT5/Y82XLlrVbTK1Ryte16wF7Ao9G6o8FXnf36939Y3d/GrgVOK3MMYpIMuWmSPooLyU1\nOpU6rN/MzgR+kr/1bGZ3AJ+6+6iCfU4ALnX3LZo7VkNDw5qTLlmypOVRS6b1799/zfNevXrFb39I\nSLlyU3kpzVFetoz+Zkp7KJaXbfleYGNgUaTuAyC+Wm8RdXV1bQgj2erVq2N1J598cqwuaS6c9dZb\nL1Y3dOjQJs914YUXctlll7UwwrBqfl1bX19fkf+D1kpa2FpapM25WVdX127XRdLXP1tsEf+bl/R1\n7apVq5o8brWv68033zxUTppL7NNPP43VFX5dW+33UEh52Wap/ptZqqR8PeOMM2J1zX1dO3/+fAYP\nHpzqr2vvvPPOWF2+y8W2227Lq6++CtBuc+Q2pVhelrvzRycgFTN+fv7557G6pAZdkn//+9+xuvwk\njknyEzu2RdLrJ0+eHKvbeuutY3VHH310qHz88cfH9ll//fXbEJ1kQGpyM6pbt26xuiz0SxswYECo\nnNTImzt3bqxu//33r1hMkjqpzcumTJkSHydy0003xeoK+9/lTZo0KfQ8LQ26pAbpqaeeGqvLT9S8\n7bbb8thjjwHVb+QV05YpVJYT/wSyUa5eRKpHuSmSPspLaXdtaeTVA9F7xoOA+PpfItKelJsi6aO8\nlHbXlu9EZgIXmdkZwG+BPYDvAweXIzARaTXlpkj6KC+l3ZUyT54DWwOdgS5m9kl+E3AIMAG4HHgT\nON3dn6xQrCJSQLkpkj7KS0mToo08d7dmNr8B7FW+cGrb17/+9VjdYYcdVtJrCzuk5iVNyvzWW2/F\n6p566qlQedasWbF9Zs+eHavTYIzaluXcPPPMM2N1P//5z6sQSesde+yxofKTT8b/lv/zn/9sr3Ck\nnWQ5LyF5AFHSVGxJM1Lk87q+vj4xx9tLdKaN6dOnx/bp2bNnrO7EE09MfJ5mWrtWREREJIPUyBMR\nERHJIDXyRERERDJIjTwRERGRDKr9aeXbyVZbbRWr+/Wvf73m+Z133sl3vvOd2D7du3cv6fg/+9nP\nYnXPP/98rC5pZYwJEyaEytGBGBBe3y7vhhtuAIIlpP7whz8AcPjhh5cUr0gllZo3CxYsiNUNHDiw\n3OG0SnTQ1SmnnBLb57bbbovVHXPMMRWLSaQS8st9FUoaJFi47u6SJUsS/y61xfz582N1F1xwQazu\niSeeCJWT4p84cWKsbtCgQUAwcCT/PO10J09EREQkg9TIExEREckgNfJEREREMkiNPBEREZEMyuzA\ni86dO8fqLrnkkljdRRddFKvba6/4hOSPPvporK5r165A0AnzqKOOak2Ya6yzzjqxur333ruk2KID\nPkaPHh3bJ6mD+ogRI4BgoEb++b333lv0+CKVtt9++8XqkmbVv/3222N1vXv3XvN86dKlfPbZZ7F9\n6uvrY3XPPfdcSbFNmzYtVrdixYqSXhuVNJCqsHN6vlzuDuoirXXooYfG6iZPnhyre+WVV2J1AwYM\nAIIBEgMGDKBPnz6xfUpdSSJplYp33nknVpc0qCL6u2TTTTeN7ZP0PmuR7uSJiIiIZJAaeSIiIiIZ\npEaeiIiISAapkSciIiKSQZkdeNGlS/ytjR07NlZ39tlnx+o++uijWF1+kEW1JXUijQ7QmDt3bmyf\nb33rW7G6v/3tb2uef/HFF0Dyihe///3vY3VJgzGSYhNpjb59+8bqkq6v66+/PlZ33XXXAfDkk09i\nZnz66aetjiOpY/jaa68dq9tss81idatWrQqV33///ZLOOXv27DXPhwwZwuzZsxN/T4lUw+DBg2N1\nSYMlkgZjFOZwp06deO+992L7jBs3LlaXNOgq6fdBqXVRc+bMidUl5X4t0p08ERERkQxSI09EREQk\ng9TIExEREckgNfJEREREMiizAy9K1aNHj5Lqasm6664bq3vkkUdidYWrZ2y//fYAvPzyy7H9hg8f\nHqtraGiI1SWt2iFSSStXrozVde/ePVT+4Q9/GNtnjz32iNUNHDgwVrfbbru1OrboShtJK9g8++yz\nrT6+SFpcffXVsbpf/vKXsbrHH398zfP777+/5ONvvPHGsbq///3vsbpTTjmlpOMdc8wxofKOO+5Y\nciy1RnfyRERERDJIjTwRERGRDFIjT0RERCSD1MgTERERyaAOP/CiLQo7Vn/22WexjtaQPAiiGtZb\nb71Y3e677x57njTwIslf/vKXWN0BBxzQyuhEwpLy5vzzz4/VDRgwIFZ36KGHAvDKK6+wbNkyNthg\ng/IHWIJu3bqFytttt11sHw28kKzq2bNnrO7ggw8GoL6+fs3zUiQNsDruuONidaWueHHjjTeWfO5a\npzt5IiIiIhmkRp6IiIhIBqmRJyIiIpJB6pNXoqT+dueeey4Q9A0499xzqa+vj+3z6KOPxuqik7VW\ny9ixYwFYsWLFmuf33HNPbL+k/hDnnXderG7YsGGhcpcuurykdZImJE+aXLWYavXHS5LUh2jmzJlV\niESktpx11lmxuldffTVW19jYGKs77LDDYnVJ/QWzSnfyRERERDJIjTwRERGRDFIjT0RERCSD1MgT\nERERySD1jC/RvHnzYnXXXXcdEHSovu666zjttNNi+6RlkEWSbbfdFggmpsw/HzhwYGy/p556Klb3\n4osvxupWr15d5ghFsiMpt5I6ij/22GNrng8ZMoTHHnuMs88+u6KxiaTFtGnTYnXTp0+P1SVNcrzp\nppvG6iZPnlyewGqU7uSJiIiIZJAaeSIiIiIZpEaeiIiISAaV1CfPzLYGrgKGAo3AXGC0uy8zs52A\nScCuwAfADOAX7h7vbCIiZaO8FEkn5aakRakDL2YDLwBfBboDdwA3mNnRwIPArcBhwNbAw8C7wJSy\nR9tO3n///VjdiBEjqhCJSLM6VF7Wut69e8fqkjqPz5kzZ83ziy++mDlz5rB48eLYfgMGDChvgFJO\nys0SJK0kNWVK/MeQNEApyX777Rer69u3b8sDy5CiX9ea2QZAPfBTd//Q3d8DbgSGAIcA6wAXuftH\n7r4ImAzEh5mKSNkoL0XSSbkpaVL0Tp67/ws4IVLdF3gb2A34u7t/UbDtOWC8mXV390/KFqmIrKG8\nFEkn5aakSadSb4PmmZkBfwVOB/YFNnH34QXbdwEWAF9x938kHaOhoWHNSZcsWdLyqCXT+vfvv+Z5\nr1694t9nSYzyUipNedk6yk2ppGJ52aLJkM1sN+Ah4Ep3v93M9k3YLX+SkluPdXV1LQmj4pL65O24\n445N7jdv3jz22GOPxMmQr7322vIHWGb19fVr/g+GDh0a2540GXKSlStXhsrdunVrVTwNDQ2tel1H\nVYm8rKurC10XtagW4l9rrXiPmS5dvvy1/PTTT7PXXnvxwgsvxPZr7z55ysuW6yh/M1sqn5tJffL2\n2muvWN1zzz0Xq0vqz3rMMcfE6m677bZWRtm0NP1uKZaXJTfyzOwA4G7gfHe/Ple9HNgusutGwCpg\nRelhpkvhL9m8UlaumDVrVkmvGz16dKxuyy23LDG61ok2wADuvvtuIGjA3nzzzQAsWLCgonFIeXWk\nvMyipAFd0d8jq1at4qWXXortp4EX6abcLO6MM86I1T3//POxuqQG3a677hqru/HGG8sTWIaUNE+e\nmQ0G7gKOL7hYIehcurOZFd6yGQQscPdPyxemiEQpL0XSSbkpaVH0Tp6ZdQF+SzAa6A+RzQ8B/wQu\nMbPLgK8BPwZ+Wu5AReRLykuRdFJuSpqU8nXtnsAOBKN/xke2GcGQ8GsIRg4tB65y91vLGqWIRCkv\nRdJJuSmpUcoUKn/my46hTflWecIRkVIoL0XSSbkpadKi0bUdxQYbbBCre/zxx2N1hSNRt9hiC95+\n++3YPhMnTozVzZgxI1a3+eabx+oOOeSQWF3SiJ6pU6eGyiNHjoztc+mll8bq3njjDSAYHXzSSSfF\ntjdn5syZsbquXbu26BgiHd0uu+wSq0sawPXQQw/F6o488siKxCRSKYUDAFeuXMm0adNi+ySNOF+9\nenWs7sorr4zV9ezZs40RZk9JAy9EREREpLaokSciIiKSQWrkiYiIiGSQGnkiIiIiGaSBFyXq169f\nrG7x4sUALFq0iMWLF3PRRRfF9rnqqqtidStWxCc2T6pbtGhRrC5p5u+oxx57rOg+TUlavm3ChAmx\numHDhsXqSolNRL40ZsyYWN2dd94ZKu+0004cfPDB7RWSSMVMmjQJgP33359JkyYlDrJI+juStN/C\nhQtjdUNzhAUZAAAgAElEQVSGDClDlNmiO3kiIiIiGaRGnoiIiEgGqZEnIiIikkFq5ImIiIhkkAZe\ntEGPHj1Cz8eNGxfb57LLLovVJa0W8fDDD8fq7rvvvjZG2Lyzzjor9nz48OGx/fbZZ5+KxiHSUa29\n9tqxuueff37N8/r6+lBZpJbNmTMHCAZezJkzJ3Eli6RBFoWrS+UdeOCB5Q8wg3QnT0RERCSD1MgT\nERERySA18kREREQySH3yyiipL0G3bt1idSeccEJJde2lvr6eK6+8smrnFxGR7Bs/fnzo+Z577hnb\nZ9ddd43VTZ06NVbXv3//8gaXUbqTJyIiIpJBauSJiIiIZJAaeSIiIiIZpEaeiIiISAZp4IWIiIhU\n3KBBg4BgsN+gQYNYtWpVlSPKPt3JExEREckgNfJEREREMkiNPBEREZEMUiNPREREJIPUyBMRERHJ\nIDXyRERERDJIjTwRERGRDFIjT0RERCSDOjU2Nrb7SRsaGtr/pFKTevXq1anaMXQUyksplfKyfSk3\npRRJeak7eSIiIiIZpEaeiIiISAZV5etaEREREaks3ckTERERySA18kREREQySI08ERERkQxSI09E\nREQkg9TIExEREckgNfJEREREMqhLtU5sZn2B64C9gI+BPwBj3P3zasVUjJntBNwBrOvu/QrqhwLj\nge2BZcBEd59SlSCbYWZbA1cBQ4FGYC4w2t2X5d7bJGBX4ANgBvALd9ccOx1ILeYlKDcl+2oxN5WX\n1VfNO3n3EfxgvgbsQ3DhXlrFeJplZiOAPwJLIvWbAbMJ/oM3BU4AxpvZge0eZHGzCX45fBXYAdgY\nuMHMegAPAs8AWwKHAicCp1YpTqmemspLUG5Kh1FTuam8TIeqNPLMrI6g9fsTd/+Xu78B/Ao4xczS\n+hXyesCewKOR+mOB1939enf/2N2fBm4FTmvvAJtjZhsA9cBP3f1Dd38PuBEYAhwCrANc5O4fufsi\nYDIpew9SWTWal6DclIyr0dxUXqZAtb6u3Q1Y6u7vF9Q9B2wIbEuk5Z8G7v5bADOLbtqNIPZCzwHD\n2yGskrn7vwg+MRXqC7xN8B7+7u5fFGx7juDTVXd3/6SdwpTqqrm8BOVmO4Up1VVzuam8TIdqfQLY\nGFgRqfsg99i7nWNpq6beS6rfhwWZdyHB7f6m3sNaBL9EpGPIUl6CclOyI0u5qbxsR2m6zdsp95iq\nTout1IkUvw8z2w14ErjS3W9vYrcs/X9I62XtOlBuSlZk6TpQXlZItRp5y4m32jcq2FZLmnovqXwf\nZnYA8Bhwsbv/Ilfd1HtYRfzTimRXlvISlJuSHVnKTeVlO6pWI68e2MLMNi+oGwS8B7xWnZBarR6o\ni9QNAuZVIZZmmdlg4C7geHe/vmBTPbCzmXUrqBsELHD3T9szRqmqLOUlKDclO7KUm8rLdlSVgRfu\nvsDM5hF0UvwRwffbFwLXpm2OmRLMBC4yszOA3wJ7AN8HDq5qVBFm1oUgvovc/Q+RzQ8B/wQuMbPL\nCIbo/xj4aftGKdWUsbwE5aZkRMZyU3nZjjo1Nlbn+jCzrwC/IZjv5z8EreUL3H1VVQIqwswc2Bro\nTNA4zrfWjWCenAnAjsCbwHh3v7UacTbFzL5B0Kcg6VOGAT2Bawg+YS0HbnD3Ce0XoaRBreUlKDel\nY6i13FRepkPVGnkiIiIiUjlpGl0rIiIiImWiRp6IiIhIBqmRJyIiIpJBauSJiIiIZJAaeSIiIiIZ\npEaeiIiISAapkSciIiKSQWrkiYiIiGSQGnkiIiIiGaRGnoiIiEgGqZEnIiIikkFq5ImIiIhkkBp5\nIiIiIhnUpdoB1DIz2xeYC1zi7heX+diNwBPuvm8rX/84MLSg6iB3/2OJrz0NuL6gaoa7j2pNHCLt\nLcN5eSDwcEFVq+MQqYYM5+Y44LyCqrK/v9bqMI08MxsF3ARc4O7jqhxOezo697gAwMw+AtZpYt93\n3X0zYE7udZsAv6l4hNJhKS+DvIwyswHAQqCbu3cq2Df/ulmVDU86OuXmmr+ZawPnAt8DtgVWAk8A\n/+3uL+f2nQnUAzsAF7dnsMV0mEZeR+Xu9+Sfm1kXggbeM8BVCbt/knvNa8BrZtavPWIU6WgK8zLK\nzDoBNwLdIq95F7gnt09F4xPpqCJ/MzsDDwHfBP4ETALWJbhr94yZ7eHui939ReBFM3u/GjE3R428\njmWD3OPLzf2REZGqOhXYG3ge2KXKsYh0ZCMIGnh/AIa7eyOAmT1IcKf9KuDg6oVXnBp5CSz4mHwB\n8G2CryyXE9y6vdjd/9bEa74DXERwu/YTgr4z57j7O5H9DgfOBnYl+Pn/L3AHMMHdP2kmpvUpPlBm\ntbt/2Mz2fCOvochxRFInw3lZeLyvAOMIvv5ZjRp5UgMynJsH5R4n5xt4AO7uZnYP8D0z6+Pu7xU5\nT9VodG2EmW0B/AU4DLgW+AEwEdgZeMrM6hJetgdB37XZwJnA74GRwENmtuZnbGY/ym1rJPiO/0yC\nRLgEuD/3NU1TXgBWFPn3QpG3l2/k/SsXT2cz61HkNSJVl/G8LHQtsAo4pwWvEamajOfm5rnH1xK2\nPU/QhtqtyDGqSnfy4nYg+I+f5u535CvNbCHwR+A04KTIa74J7OTunitPN7OuwLEEnwQeNLNNgV8D\nDwKHFnwq+K2Z/YPgl/oRwO+aiOsYoHuR2Jv8VJOTb+TtZGZ/BvYEOufOfyvBiKCVRY4hUg1Zzsv8\nexkODAdOdPfl6ncnNSLLuZn/1msT4PXIto9zj1sXOUZVqZEX4e5zCEaXAmBm6wBdgTdzVf0SXvZE\nwcWadzfBBbsfwUV6GMEFdyfQK/IL/D6CC3Zfmrhg3X1ey95Jonwj7xCCT1yXA71zcf4U2NvM9nX3\nL8pwLpGyyXhe5r9auhZ4kmBEo0hNyHhu/hn4L+AoYM3Xzrm7jSNyxXXLcJ6KUSMvQe4T9Y+AQcSn\nG0n6mb2YUJe/vZtv5W+fe7y1mVNvVWqMrfQ0waekV9z9lYL6W8zsPoK7CCOBWyoch0iLZTgvIbhj\n0RsYVtj3R6QWZDg3pxL0BxxjZssJGpfrA+cXnPvTCsfQJmrkRZjZicA0YCnBfDcvEcyLsxFwbxMv\n+3dCXf5Wbr7P23q5xzEE3+UnWdFMXBsCnZvanrPK3Zs8hrsvA5Y1sflagkbe/qiRJymT5bw0s32A\nU4BL3X1xkWOJpEqWc9PdPzGzYcDtwITcv9UE7+sCggEgHxQ5R1WpkRf3E4KOz99y9//JV1rzHWR6\nNlOX7+OWv6iXufvjrYhrAcW/+3+D5FvjpXg397h+K18vUkmZzEsz60YwJ97rwAwz2zIaa77O3d9q\nRXwilZbJ3MzLfes1yMy+TtBwfTXXZ/ZHuV1ebvrV1adGXtw2wJuFF2vOkGZes11C3ddyj/lb0Ity\nj3sT9D1YI/eLvnuRodxt7kRqZnsTTMlws7v/J7o59/gmIumT1bz8CjAg9/zVJvZZmntsbiShSLVk\nNTdDEt7fQQRTxSws9RjVoEZe3LtAHzPrmR9pamZ9CfobwJe3kgsNM7Nt3b3wl/TI3OOjucf7Cb4S\nPdbMfhmZV2c08Asz+7a7P5kUVJk6kX4b+DnBe7giX5kb1XRurnhfGc4jUm5Zzct3gUOb2DYaGNbM\ndpE0yGpu5m+M3ANMd/exBfVDgAOBX7n7qraep5I6YiNvRzM7qoltzwN3ETR47jWz24EtgB8TXFRX\nA7uY2WkEo3/yniCYD+gagj5vBxGsf/cM8P8A3P09MzuPYP6gp81sMsHw7CHAKIJRPE+X8X0muZpg\nRNB4M9uOYG6jXsDxwEBgqrvPrXAMIkk6ZF66+8fAA0nb8j8Pd0/cLtJOOmRu5swD3gHON7P1gPkE\nd97z/QRTv6ZvR2zkfT/3L8kYgo6j3YEjgesJRgGd5u73m9m6BHfALifoXJr3MHAdwezd2xP0KbiF\nYPbuwlmyJ5nZG7nzXJY7z+u5411e6alL3P1fuU8mPyG4lX0cwcigF4BR7j6jkucXaUaHzUuRlOuw\nuenuq8xsf+CXBAMTTwX+AUwhmFf2o0qevxw6NTZqtH4WmdnjwFB3b3U/HjPrR7CEzAx3H1WeyEQ6\nrnLkZe44jQRzje1bjrhEOroy/c3cF5hL0AC8uDyRtY2WNRMRERHJoI74dW2HUtCX4s/u/m6zO3/5\nmq8SLAa9ScUCE+nAWpmXmwLfqFxUItLK3NyRoK/eDhULrJXUyMu+WbnHgwjWESzFtwn6VohIZbQm\nLwcWvE5EKqM1uXkscF5lwmkb9ckTERERySD1yRMRERHJIDXyRERERDJIjTwRERGRDNLAixKY2U7A\nT4F9CNaa/JBgpu1fufv8gv3WJeh8+X2CWb/fI1jX7tLC/Vp47j7A2cDhBIstf0EwefFv3P32yL5r\nEaxeMZpgLdqPgCXANcCdhZNMimSBclMkfZSX6aE7eUWY2Z4ES5t8E7gROCn3uB/wZzPbK7dfD4Jl\nws4nWJblFIIRqrsTLMlySCvOvQnB0i0/JhjlcxrwC4Kkuc3Mzo28ZApwE8Fagj8mmIm8B3A7wQzh\nIpmh3BRJH+VluuhOXnFTgE7A3u7+er7SzP4K/A44i+ATyhjg/xAsy3JVwX4PEqxxdxHhtftKcSHw\ndeC77n53wTHvAP6HYHmyCbm6vYCTgdnufljBvjcDi4Gzzexyd29oYQwiaaXcFEkf5WWK6E5eM3K3\ncmcAZxVerDmP5B63zT1+CNwLTC/cyd0XEizAvFPumH3MbLmZvZr7JFN4vvPMrNHMLshV/YXgQr8v\ncsy3CdYB7JO73Q2wDnAHuQu4YN//AE8CXQkmaxSpecpNkfRRXqaP5slrJTPbDagHbnH3HzSzX2fg\nn8AKd98mV/dd4E7gl+5+Ya6uL/AywYW4p7uvauaYPQgWaf7E3bcuIdYHgEOAfu7+RmnvUKQ2KTdF\n0kd5WR36urYFzGwDYF2CzqRXAP9L8B1+c0YBvQi+9wfA3e/KLZ1yrpnNdPfFwGSC/48fJF2suU8f\n6xAsm3JJLo4TSoh5O2B/YEGtX6wiTVFuiqSP8rL69HVty6wAlhJ0yvwTsLu7/29TO+c+uUwG3gAu\njWz+v0ADcH2ug+kRwM/d/eUmDvcA8A7wKNAIDHb3ZvsrmNlGfHnb+ozm9hWpccpNkfRRXlaZGnkt\nsx/wHeDnBOva1ZtZXdKOZrY/MJdgSPYh7v5B4XZ3X05wEe1LcBt6HnBlM+ceDRxAcKGvA8wzs+Ob\n2tnM+hF0bv0awSedZ4q/PZGapdwUSR/lZZWpT14r5S6I54D3gQHuvrpg2w+BqQSfYA509yVNHGPt\n3D6bAGe6+3Ulnrs78BhQB2zn7q9GttcRfIpZDzjG3We37N2J1C7lpkj6KC+rQ3fyWik3cuhRoD9f\njhbCzMYQjBZ6FtijqYs15xdAb4LOo5eY2aYlnvsT4DaC0T/fLNxmZvsAT+SKQ7J0sYqUQrkpkj7K\ny+pQI68ZZradmS01s+lN7LJB7rFLbv/jCW4f/xEYlru93NSxBwHnEHx6GU7QKXRKwfZOZva8mXkp\n5869ZidgNsGs4Xu5+7NF3qJITVJuiqSP8jJ91Mhr3hKgO3C0mW1TuMHMtgX2BpYD/2NmAwguvr8C\nR7r7yqYOmrvlfDPBhXW+uzvB7NpHmNn3AXLLqfwv8PXcqKLC13cDjskVnyo45t3AauBb7v5aG963\nSNopN0XSR3mZMuqTV4SZHUNwm/efwHXAa8A2BB1A+wAnuPtNZnYvcCTB8PBFTRzuCXdfbmbjCdb1\nO8rd782dpxvBmn19gB3c/R0zM4KOoOsBNxDMMdQL+CHBTOEz3H1U7vU/IhiVNIvgwk3ykru/1Mof\nhUiqKDdF0kd5mS5q5JXAgrX4ziP4FLIBwUzdfwOucvc5uX1eJ1gMuTn7ASsJLsIH3f3wyHmGAI8T\nLLNyeK5uK2AscCCwOfAZweSPNwNT8p1XLViKpckJJnMucfeLi+wjUjOUmyLpo7xMDzXyRERERDJI\nffJEREREMkiNPBEREZEMKsvatRYsFHwdsBfwMfAHYIy7f16O44tIyykvRdJHeSntqSyNPIK13hYR\nLAfSC/gdwbpz5yft3NDQoI6AUpJevXp1qnYMNUx5KRWhvGyTFuUlKDelNEl52eaBF7nlQOYDm7r7\n+7m6owiGL/cuXLokTxeslEp/TFpHeSmVpLxsndbkJSg3pTRJeVmOPnm7AUvzF2zOc8CGFCxdIiLt\nSnkpkj7KS2lX5fi6dmNgRaTug9xjb4IZsJu0ZEmzm6UD6t+/f7VDyALlpZSV8rIs2pSXoNyUsGJ5\nWa4+eVH5W4Yl3WKuq6urUBgdU319fU3/TBsaGqodQlYpL6tIeSlNaFFegnKz3Go5N4vlZTm+rl1O\n8Amk0EYF20Sk/SkvRdJHeSntqhyNvHpgCzPbvKBuEMFCwplc8FekBigvRdJHeSntqs2NPHdfAMwD\nxptZLzP7KnAhcK27a0SQSBUoL0XSR3kp7a1cK14cBawPvArMBR4EflWmY4tI6ygvRdJHeSntpiwD\nL9x9GXBEOY4lIuWhvBRJH+WltCetXSsiIiKSQWrkiYiIiGSQGnkiIiIiGaRGnoiIiEgGqZEnIiIi\nkkFq5ImIiIhkkBp5IiIiIhmkRp6IiIhIBqmRJyIiIpJBauSJiIiIZJAaeSIiIiIZpEaeiIiISAap\nkSciIiKSQWrkiYiIiGSQGnkiIiIiGaRGnoiIiEgGdal2ACIin376aag8YsSIUPnSSy8NlXfeeeeK\nxyQiUut0J09EREQkg9TIExEREckgNfJEREREMkiNPBEREZEM0sCLiC+++CJUvuOOO2L7jBo1KlQ+\n66yzQuV+/fqFys8++2zsGDNnzmw2jtWrV4fKa60Vb48fd9xxoXJh5/SlS5fSt2/fZs8hkhbR6/2R\nRx4JlY866qhQWQMvRESK0508ERERkQxSI09EREQkg9TIExEREcmgDt8nL9oXaMyYMaHy9ddfH3tN\np06dQuXJkye3+LzRY0RF++Al7R/t1/fGG28AMGHCBI4//njmzp3b4rhEqqFHjx6h8ve+971Q+a67\n7gqVo330ko4hIrVp/vz5sbrTTz89VF64cGGo3KdPn1D5xBNPLPl8RxxxBBdeeGGs/tRTT43V1Vpf\nd93JExEREckgNfJEREREMkiNPBEREZEM6vB98pYvXx4qJ/XBaw+9e/cOlaP9C1atWhV7jbtXNCaR\naon2p/nGN74RKl9wwQWx10ycOLGiMZXqzTffDJVnzZoFwNChQ7nyyis555xzqhGWSGqNHj06VJ4+\nfXpsn//85z+hcrSf+nvvvRcqjxs3LnaMxsbGxGMcccQRjBs3LrZ90aJFsWNMnTo1VI7+rU4b3ckT\nERERySA18kREREQyqKSva81sJ+AOYF1371dQPxQYD2wPLAMmuvuUCsQpIgmUmyLpo7yUtCjayDOz\nEcDVwF+BgQX1mwGzgfOAm3PbHjaz1939jxWJtgw+//zzUHn//fdv8TG23377UHns2LGh8tZbb93i\nY0bXu91ss81C5eiauhBf3/Pjjz9e8/xHP/pRi2OQ2pK13CzUrVu3Zrdfc801sbq09MkbPHhwqJzv\nKzR//nx++tOfqk9exmU5L1uroaEhVP7BD34QKt9///2hctK8sNtss02ofPvtt4fKgwYNanV89fX1\nfPHFFxxxxBHNxgXx/vO/+c1vQuWuXbu2Oo5KKOXr2vWAPYFHI/XHAq+7+/Xu/rG7Pw3cCpxW5hhF\nJJlyUyR9lJeSGkXv5Ln7bwHMLLppN+C5SN1zwPCyRCYizVJuiqSP8lLSpC1TqGwMRMcXfwD0Tti3\nWfX19W0Io22ShmpXw1tvvdVsOckmm2zS5Latttqqqj/Xtujfv3+1Q6h1ZcnNNF0/ScscRaUl3tmz\nZze5bf78+amJs6WUl22Wib+Z5RBdQixpSbGWauvPpL6+vlVxRZdXa2/F8rLc8+R1AhqL7hVRV1dX\n5jCaFu2Tt9tuu4XKL730UtFjpL1P3lZbbcWbb77JkUce2eI40iDaf0PKosW52Z55GRX9hR3t55Yk\naS7Jath8881D5cI+eYMHD05NnC2lvKyI1P/NLIda6JNXV1cX65OX9IHthBNOCJWr3SevWF62pZG3\nnPgnkI1y9anVuXPnUHn33XcPlaONvGiDDmDevHmhcs+ePcsUXdO6dIn/Vx100EGJ+9bX19dsA0/K\noiZzsznRSUrTLBprYbmW3oeUXebyMkl0UmKI3wh54IEHQuVoo+6kk06KHePqq68OlSvxd3fGjBmh\n8i233BLb5/LLLw+VV65cGSr36tWr7HG1RVvmyasHoh8nBgHzEvYVkfaj3BRJH+WltLu23MmbCVxk\nZmcAvwX2AL4PHFyOwESk1ZSbIumjvJR2V8o8eQ5sDXQGupjZJ/lNwCHABOBy4E3gdHd/skKxikgB\n5aZI+igvJU1KmUIlNg68wBvAXuULJ32WLl0aqxs5cmTZzzNkyJBQedSoUaHyRhttVPZzSm3Lcm7u\nvPPOofLGG28cKn/wwQftGU6LRPsXFZY7deoUG0SV1N9WaleW8zLJZ599FipH+98BTJs2LVRea61w\nT7Gnn346VC5loFUlPPzww6Fynz59YvssW7asvcIpC61dKyIiIpJBauSJiIiIZJAaeSIiIiIZ1OE6\ng0QnQ47OixP173//O1YXneOnHKLHnDx5cqicNMHy0UcfHSoff/zxa55/+OGHrL/++mWMUKT9dOvW\nLVSupX5rAwYMCJWj84bNnTs3VN5///0rHpNIpUyZMiVUvummm2L7RPvgTZo0KVSuVh+8fF/BXXbZ\nhWnTpnHqqaeGtifN1/fd7363XWIrF93JExEREckgNfJEREREMkiNPBEREZEMqp2OLjXk61//eqh8\n2GGHFX1NtI9CdH6+t956K/aap556KlSeNWsWAFdeeSWHHnpobHFl9dGTWnXmmWeGyj//+c+rFElx\nxx57bKj85JPhuW7/+c9/tmc4IhUV7XOatD7z0KFDQ+VoPreXk08+OVSePn06APPnz+fUU0+NrYd7\n4okntltslaI7eSIiIiIZpEaeiIiISAapkSciIiKSQWrkiYiIiGSQBl60wlZbbRUq//rXvw6Vv/Od\n74TK3bt3L3rMn/3sZ6Hy888/HyonTcA8YcKEULlwIMZTTz1F//79Q9tvuOGG2DEOP/zworGJVFsp\nObRgwYJQeeDAgZUKp1nRgVannHJKqHzbbbeFysccc0zFYxJpL506dYrVRQcOLlmyJFSO/q1qjfnz\n54fKF1xwQWyfJ554IlQujLVTp05MnDgxtH3QoEFtjqvadCdPREREJIPUyBMRERHJIDXyRERERDKo\nw/XJ69y5c6h8ySWXhMoXXXRRqLzXXnvFjvHoo4+Gyl27dm1zXOuss06ovPfeexeNI9r3b/To0Wue\nDxw4MNZHacSIEbFj3Hvvvc0eUyQN9ttvv1A5acLV22+/PVTu3bt3qPzZZ5+FyvX19bFjPPfcc83G\nkV/QPG/FihXN7h/V2NgY618b7Z8E5emjJNIeDj300FB58uTJsX1eeeWVUHnAgAGhcp8+fULlUiYh\nzk9knPfOO++Eykl9A6O/NzbddNNQDNH3kgW6kyciIiKSQWrkiYiIiGSQGnkiIiIiGdQpqW9LpTU0\nNKw56ZIlS6irq2v3GJry8ccfh8offfRRbJ9NNtmkvcJpkXysixcvZsCAAXzrW98Kbf/b3/5W9Bi/\n//3vQ+VoH72kfg7l1tDQsOZ5r169Kn9CAdKdl8uXLw+VN9tss9g+PXr0CJVXr14dKn/66actPm+0\nr1Ap1/+qVatC5ffffx8I5vEaPHhwrF/QFVdcETvG2Wef3dJQK055WT1pzs2oMWPGxOqi/fSieRTN\niVL605XjGAsXLgTgk08+oXv37uy4446x16RdsbzUnTwRERGRDFIjT0RERCSD1MgTERERyaAON09e\nMdF+PdFymq277rqh54888khoe9Jcey+//HKoPHz48FC58Pt+iM/nJ5IWK1euDJWj693+8Ic/DJX3\n2GOP2DGi693utttuLY4jOh9f4ZyXu+66K88++2yLjylSK66++upY3S9/+ctQ+fHHH2/xcTfeeONQ\n+e9//3uoHF0jOkl0neh8H7z6+vqa7I9XCt3JExEREckgNfJEREREMkiNPBEREZEMUiNPREREJIM0\n8KIMoh2to+XCARHtab311guVd99999g+0YEXUX/5y19C5QMOOKDtgYm0UDSHzj///Ng+0UXPo4uN\nb7DBBuUPLEG3bt1C5e222y70XAMvpKPp2bNnqHzwwQe3+BjRgVXHHXdcqByd/DhpMuQbb7yxxeet\ndbqTJyIiIpJBJd3JM7OtgauAoUAjMBcY7e7LzGwnYBKwK/ABMAP4hbu3/3ppIh2I8lIknZSbkhal\n3smbDXwMfBXYAdgYuMHMegAPAs8AWwKHAicCp5Y/VBGJUF6KpJNyU1Kh6J08M9sAqAcudPcPgQ/N\n7EbgBuAQYB3gInf/AlhkZpOB04AplQu7uqJ97s4999xQub6+PlR+9NFHY8eITtTaHsaOHRuru+ee\ne0LlaL+H8847L1QeNmxY7BhduqhrZ3vraHkZnZQ8OrlqmhX2HTruuOOYOXNmFaORSutoudlezjrr\nrFD51VdfDZUbG8M3Qg877LDYMaJ9AzuCon+d3f1fwAmR6r7A28BuwN9zF2vec8B4M+vu7p+ULVIR\nWUN5KZJOyk1Jk07R1m8xZmbAX4HTgX2BTdx9eMH2XYAFwFfc/R9Jx2hoaFhz0iVLlrQ8asm0/v37\nr3neq1ev+BApiVFeSqUpL1tHuSmVVCwvW/Q9m5ntBjwEXOnut5vZvgm75U9Scuuxrq6uJWFUXdq/\nrq2vr0/8mUZvb0N8rc7o17XR9fyi7w3K/3VtdL1caZ7yMt3ya0hvuOGGrFixIjYN0RVXXBF7zdln\nn7pyeV0AAAmMSURBVN0usbWE8rLllJvlc/LJJ4fK06dPD5WjN6wOP/zw2DF+97vfJR67qb+ZtaBY\nXpb819nMDgDuBs539+tz1cuB7SK7bgSsAlaUHmZtmTdvXqh83XXXhcqnnXZaqFyN/ndJtt1221hd\ntJH31FNPhcovvvhiqLx69eryByatprxMv3yOvf766wwcODD2x+ixxx6LvSaNjTxpGeVm602bNi1W\nF23URefB23TTTUPlyZMnlz+wGlTS6FozGwzcBRxfcLFC0Ll0ZzMrnP1zELDA3T8tX5giEqW8FEkn\n5aakRSmja7sAvyUYDfSHyOaHgH8Cl5jZZcDXgB8DPy13oCLyJeWlSDopNyVNSvm6dk+CeX7Gm9n4\nyDYjGBJ+DcHIoeXAVe5+a1mjFJEo5aVIOik3JTVKmULlz3zZMbQp3ypPOOnz/vvvx+pGjBhRhUhE\nvtTR87KW9O7dGwj65PXu3TvWl2jOnDmx1yxevDhUjq7LK+ml3Gy56GDGKVPiUwYWmwlkv/32C5X7\n9u3b9sAyQGvXioiIiGSQGnkiIiIiGaRGnoiIiEgGqZEnIiIikkFaWb6IpNUcik1uPGvWrKL7jx49\nOlTecsstWxFd86KrV9x9992xfRYsWFD284pI06IDt6K/LwBeeumlUFkDLyTLzjjjjFD5+eefj+0T\nHbC06667hso33nhj+QPLAN3JExEREckgNfJEREREMkiNPBEREZEMUp+8IjbYYINY3eOPPx4qDx06\nNFR+++23Q+WJEyfGjjFjxoxQefPNNw+VDznkkFC5rq4udoypU6eGyiNHjgRgxx135Oabb+bSSy8N\nbX/jjTdixyhm5syZoXLXrl1bfAwR+dIuu+wSKif1yXvooYdC5SOPPLKiMYm0p2h/8WnTpoXKa60V\nv/+0evXqUPnKK68MlXv27Fmm6LJFd/JEREREMkiNPBEREZEMUiNPREREJIPUJ68V+vXrFypHFxO/\n6KKLQuWrrroqdowVK1Y0W160aFGoHJ0jKMljjz0GwLx58zjppJOK7g9B/71CEyZMCJWHDRvW4jhE\npGljxowJle+8887YPgcffHB7hSPS7iZNmhQqR/vgJf2die6zcOHCUHnIkCFlii5bdCdPREREJIPU\nyBMRERHJIDXyRERERDJIffLKoEePHqHyuHHjQuXLLrss9pro/HMPP/xwqHzfffeVKbovnXXWWbG6\n4cOHh8r77LNP2c8rIl9ae+21Q+WkdTpFsmzOnDmhcnQOvKR58qLz0R544IHlDyyDdCdPREREJIPU\nyBMRERHJIDXyRERERDJIjTwRERGRDNLAiwqIdhrt1q1bbJ8TTjih2XJb1NfX88UXX5TteCIiIuUy\nfvz4UHnPPfcMlXfdddfYa6ZOnRoq9+/fv/yBZZDu5ImIiIhkkBp5IiIiIhmkRp6IiIhIBqlPnoiI\niLSbQYMGhcqrVq2qUiTZpzt5IiIiIhmkRp6IiIhIBqmRJyIiIpJBauSJiIiIZJAaeSIiIiIZpEae\niIiISAaVNIWKme0BjAcGAiuBucAYd3/HzIbmtm0PLAMmuvuUCsUrIjnKS5F0Um5KWhS9k2dmGwJz\ngPuAjYGdgc2BKWa2GTAbmAFsCpwAjDezAysWsYgoL0VSSrkpaVLKnby1gbPc/aZc+T0zuw8YAxwL\nvO7u1+e2PW1mtwKnAX8se7Qikqe8FEkn5aakRtFGnru/A9wEYGadAANGAXcCuwHPRV7yHDC8JUHU\n19e3ZHcpQS3/TPv371/tEFJPeVmbavlnqrwsjXKzNtXqz7RYXpa8rJmZ7Qw8S/AV743AhcDDwKLI\nrh8AvVsSZF1dXUt2lyLq6+tr+mfa0NBQ7RBqhvKydigvOxblZu2o5dwslpclj6519xeAbsAOwADg\njiZ27QQ0lnpcEWk95aVIOik3JQ1aNIWKuze6+2LgAuBooDPxTyAbAcvLE56IFKO8FEkn5aZUWymj\na482s2cj1atzjw8B0Xucg4B5ZYhNRJqgvBRJJ+WmpEkpffKeAr5mZj8DrgDWAy7O1d8C/MzMzgB+\nC+wBfB84uCLRikie8lIknZSbkhqdGhuLdwUws8HAVcCuwIfAY8BP3P1tM9sbmADsCLwJjPf/3969\nu9hVRXEc/46IrxSjJo2PIKiwCtEmIYL4KC3Ef8EigrERFEQQBCURQcQiihGSSgKijSBBsFKw0GaI\ngSCyiAgiWkSJGVFUNEyKPcJlMhMOOfvePeec76e5sM8wLDb7N7POPo+befxyv291ddX7D9TJ8vLy\nUusatitzqVbM5eWZTbWwWS47NXm1uWDVlf9MFsdcqitzuVhmU11slku/u1aSJGmEmuzkSZIkab7c\nyZMkSRohmzxJkqQRssmTJEkaIZs8SZKkEbLJkyRJGiGbPEmSpBHq8rVmcxERu4F3gAeAv4CPgecy\n899WNQ1NRNxBeav6I8Aa8DnwbGb+HBH3Aocpb1w/B7wHHMxM35mjLZnL/sylajOXdUwxmy138j6i\nTOTdwIOUxXuoYT1DdIIS+DuBe4CdwNGIuB74BPgKuB14HHgSONCoTg2HuezPXKo2c1nH5LLZpMmL\niL2Ubvn5zDyfmT8ArwFPRYSXkDuIiBuBFeCFzPw9M88Cx4CHgceAHcDLmflHZn4DvAU83axgbXvm\nsj9zqdrMZR1TzWary7V7gB8z89eZsZPATcBdwJkmVQ1IZp4H9m8Y3g38RJnf05n538yxk8DrEXFd\nZv69oDI1LOayJ3OpOTCXFUw1m63OAnYCv20YO7f+uWvBtYxCRATwEmULf6v5vYryh0HajLmszFyq\nAnM5B1PJ5nba6l1a/xz0TY4tRMQe4Avgzcx8f4sfc351JVw3V8hcao5cNz1MKZutmrxfuPQM5OaZ\nY+ooIh4FPgNeycyD68Nbze8FLj1bkf5nLisxl6rIXFY0tWy2avJWgNsi4paZsX3AWeD7NiUNT0Tc\nD3wIPJGZ784cWgHui4hrZsb2AV9n5j+LrFGDYi4rMJeqzFxWMsVsLq2ttdmJjIgvge+AZyjXw08A\nH2Smj4V3EBFXA6eAY5l5eMOxa4FvKYv5Vcpj959Snio6vuhaNRzmsh9zqXkwl/1NNZstm7xbgSOU\nd/78SZncFzPzQpOCBiYiHqLcU7DZWUYANwBvA3spW9FHM/ONxVWoITKX/ZhLzYO57G+q2WzW5EmS\nJGl+ttPTtZIkSarEJk+SJGmEbPIkSZJGyCZPkiRphGzyJEmSRsgmT5IkaYRs8iRJkkbIJk+SJGmE\nLgKOd98THEuHjQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe982aca278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 3\n",
    "indexes = np.random.choice(X_train.shape[0], N)\n",
    "fig, ax = plt.subplots(2, N, figsize=(10,6))\n",
    "\n",
    "for num, idx in enumerate(indexes):\n",
    "    ax[0, num].imshow(X_train[idx])\n",
    "    ax[0, num].set(title=\"Label={}\\n{}x{}\".format(y_train[idx], *X_train[idx].shape))\n",
    "    \n",
    "    X_resize = image_border(X_train[idx], 2, 0)\n",
    "    ax[1, num].imshow(X_resize)\n",
    "    ax[1, num].set(title=\"Label={}\\n{}x{}\".format(y_train[idx], *X_resize.shape))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resizing train images: 100%|██████████| 60000/60000 [00:01<00:00, 32133.48it/s]\n",
      "Resizing test images: 100%|██████████| 10000/10000 [00:00<00:00, 30924.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New X_train shape: (60000, 32, 32), new x_test shape: (10000, 32, 32)\n",
      "y_train shape: (60000, 1), y_test shape: (10000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# resize all the training and test images\n",
    "n_train = X_train.shape[0]\n",
    "n_test = X_test.shape[0]\n",
    "\n",
    "\n",
    "def resize_images(images, description):\n",
    "    \"\"\"\n",
    "    Iterates through lowest order dimension, and resizes images\n",
    "    \"\"\"\n",
    "    new_images = np.zeros((images.shape[0], 32, 32))\n",
    "\n",
    "    for index in tqdm(range(images.shape[0]), desc=description):\n",
    "        new_images[index] = image_border(images[index], 2, 0)\n",
    "        \n",
    "    return new_images\n",
    "\n",
    "X_resize_train = resize_images(X_train, \"Resizing train images\")\n",
    "X_resize_test = resize_images(X_test, \"Resizing test images\")\n",
    "X_train, X_test = X_resize_train, X_resize_test\n",
    "\n",
    "print('New X_train shape: {}, new x_test shape: {}'.format(X_train.shape, X_test.shape))\n",
    "print('y_train shape: {}, y_test shape: {}'.format(y_train.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-Normalizing images, and converting labels to one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-normalizing X data..\n",
      "Converting y variables to one-hot encoding..\n",
      "New X_train shape: (60000, 32, 32, 1), new x_test shape: (10000, 32, 32, 1)\n",
      "y_train shape: (60000, 10), y_test shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "# Input images need to be Z-normalized, and need to be flattened to 1-d vector and re-squared afterwards\n",
    "X_train, X_test = z_norm_X(flatten_images(X_train), flatten_images(X_test))\n",
    "X_train, X_test = square_images(X_train, 32, 32), square_images(X_test, 32, 32)\n",
    "\n",
    "# y values need to be converted to one-hot\n",
    "y_train, y_test = onehot_encode_y(y_train, y_test)\n",
    "\n",
    "# Need to add explicit shape of 1 as we have 1 channel for B&W images\n",
    "X_train, X_test = X_train[:,:,:, np.newaxis], X_test[:,:,:, np.newaxis] # Need explicit single channel \n",
    "\n",
    "print('New X_train shape: {}, new x_test shape: {}'.format(X_train.shape, X_test.shape))\n",
    "print('y_train shape: {}, y_test shape: {}'.format(y_train.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Our channels are in the least significant order of the np array (32, 32, 1). \n",
    "# Make sure the current backend matches this ordering, and doesn't expect (1, 32, 32).\n",
    "assert K.image_data_format() == 'channels_last'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet-5\n",
    "\n",
    "This is the best performing network, found on page 7 of [1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1, 1, 120)         48120     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1, 1, 120)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 120)               14520     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                1210      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 66,422.0\n",
      "Trainable params: 66,422.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, Activation, AveragePooling2D, Flatten\n",
    "\n",
    "def lenet5_model(verbose=False):\n",
    "    \"\"\"\n",
    "    Creates and returns a lenet5 model\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters=6, kernel_size=(5, 5), strides=(1, 1), input_shape=(32, 32, 1))) # C1\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2))) # S2\n",
    "    model.add(Activation('tanh'))\n",
    "\n",
    "    model.add(Conv2D(filters=16, kernel_size=(5, 5), strides=(1, 1))) # C3\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2))) # S4\n",
    "    model.add(Activation('tanh'))\n",
    "\n",
    "    model.add(Conv2D(filters=120, kernel_size=(5, 5), strides=(1, 1))) # C5\n",
    "    model.add(Activation('tanh'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(120)) # F6\n",
    "    model.add(Activation('tanh'))\n",
    "\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    if verbose:\n",
    "        print(model.summary())\n",
    "    return model\n",
    "    \n",
    "lenet5 = lenet5_model(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Compiling model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_4 (Average (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 1, 1, 120)         48120     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1, 1, 120)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 120)               14520     \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                1210      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 66,422.0\n",
      "Trainable params: 66,422.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "\n",
      "Training model\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.2679 - acc: 0.9209 - val_loss: 0.1157 - val_acc: 0.9669\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.0897 - acc: 0.9721 - val_loss: 0.0891 - val_acc: 0.9722\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.0604 - acc: 0.9815 - val_loss: 0.0706 - val_acc: 0.9788\n",
      "Epoch 4/20\n",
      "14080/48000 [=======>......................] - ETA: 3s - loss: 0.0457 - acc: 0.9869"
     ]
    }
   ],
   "source": [
    "# Create a new model every time\n",
    "\n",
    "def evaluate_model(model, optimizer, cv_split=None, verbose=False):\n",
    "    \"\"\"\n",
    "    Wrapper method to create, train and optionally CV, and check performance on test set\n",
    "    \"\"\"\n",
    "\n",
    "    if verbose:\n",
    "        print('\\nCompiling model')\n",
    "        model.summary()\n",
    "        \n",
    "    model.compile(optimizer=optimizer,\n",
    "                   loss='categorical_crossentropy', \n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "    if verbose:\n",
    "        print('\\nTraining model')\n",
    "    history = model.fit(X_train, y_train, validation_split=cv_split, \n",
    "                        epochs=20, batch_size=256, verbose=1 if verbose else 0)\n",
    "\n",
    "    if verbose:\n",
    "        print('\\nEvaluating model')\n",
    "    score = model.evaluate(X_test, y_test, batch_size=256)\n",
    "\n",
    "    if verbose:\n",
    "        print('\\nTest results: Loss = {:.2f}, Error = {:.2f}'.format(100.0 * score[0], 100.0 * (1.0 - score[1])))\n",
    "    \n",
    "    results = {'model': model, 'history': history.history, 'loss': score[0], 'acc': score[1], 'err': 1.0 - score[1]}\n",
    "    return results\n",
    "\n",
    "results = evaluate_model(model=lenet5_model(),\n",
    "                          optimizer=SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True),\n",
    "                          cv_split=0.2, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing results\n",
    "\n",
    "# TODO! Clean up and compare to Fig 5 in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(hist):\n",
    "    \"\"\"\n",
    "    Plots the history object returned by the .fit() call\n",
    "    \"\"\"\n",
    "    for metric in ('acc', 'loss', 'val_acc', 'val_loss'):\n",
    "        assert metric in hist.keys()\n",
    "    \n",
    "    hist_df = pd.DataFrame(hist)\n",
    "    fig, axes = plt.subplots(1,2,figsize=(14, 6))\n",
    "\n",
    "    hist_df['err'] = 1 - hist_df['acc']\n",
    "    hist_df['val_err'] = 1 - hist_df['val_acc']\n",
    "    \n",
    "    hist_df[['val_err', 'err']].plot.line(ax=axes[0])\n",
    "    hist_df[['val_loss', 'loss']].plot.line(ax=axes[1])\n",
    "    axes[0].set(title=\"Accuracy during training\")\n",
    "    axes[0].legend(labels=[\"Test\", \"Training\"])\n",
    "    axes[1].set(title=\"Loss during training\")\n",
    "    \n",
    "    for ax in axes:\n",
    "        ax.set_xticks(range(hist_df.shape[0]))\n",
    "        ax.set(xlabel=\"epoch\", ylabel=\"Accuracy / loss\")\n",
    "        \n",
    "#     return fig, axes\n",
    "\n",
    "plot_history(results['history'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation of optimizer\n",
    "\n",
    "So far we've used a stock SGD optimizer with default settings. Can we randomize our parameters and come up with a better one?\n",
    "\n",
    "It looks like it would need a lot of random guesses to get the same performance as the stock SGD we used so far. We could still try "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sgd(verbose=False):\n",
    "    \"\"\"\n",
    "    Generates an SGD optimizer with random values\n",
    "    \"\"\"\n",
    "    lr = 10 ** np.random.randint(-6, -3)\n",
    "    momentum = 0.1 * np.random.randint(8, 10)\n",
    "    decay = 10 ** np.random.randint(-5, -3)\n",
    "    nesterov = np.random.uniform() < 0.5\n",
    "    \n",
    "    sgd = SGD(lr=lr, momentum=momentum, decay=decay, nesterov=nesterov)\n",
    "    if verbose:\n",
    "        print('sgd: lr={}, momentum={}, decay={}, nesterov={}'.format(lr, momentum, decay, nesterov))\n",
    "        \n",
    "    return sgd\n",
    "    \n",
    "random_sgd(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomize optimizer and run for 100 samples\n",
    "def best_model(N=100):\n",
    "    \"\"\"\n",
    "    Returns the best model after random search for N SGD values\n",
    "    \"\"\"\n",
    "    best_result = None\n",
    "    best_acc = 0\n",
    "\n",
    "    for n in range(N):\n",
    "        print('\\nIteration {}'.format(n))\n",
    "        sgd_opt = random_sgd()\n",
    "        result = evaluate_model(lenet5_model(), sgd_opt)\n",
    "        current_acc = result['acc']\n",
    "        \n",
    "        if current_acc > best_acc:\n",
    "            print('\\n-> Updating best model. Current acc: {}, old acc: {}'.format(n, current_acc, best_acc))\n",
    "            best_result = result\n",
    "            best_acc = current_acc\n",
    "    \n",
    "    return result\n",
    "\n",
    "best_lenet5 = best_model(N=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Modernizing the network - max-pooling, relu, and dropout\n",
    "\n",
    "Since [1] was published, new layer types have been invented to improve ease-of training, and reduce overfitting. Let's retrofit the original network with these new improvements, and see how the performance changes.\n",
    "\n",
    "When creating Dropout layers in between the activation and convolutional layers, it's not clear how many to use, and what the dropout percentage should be. Let's pass in configurations to the model creation method so we can try different combinations later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import MaxPooling2D, Dropout\n",
    "\n",
    "def lenet5_modern_model(dropout_cnt=0, dropout_val=0.5, bias_init=None, verbose=False):\n",
    "    \"\"\"\n",
    "    Creates and returns a lenet5 model with retrofitted modern layers:\n",
    "    - ReLU activations\n",
    "    - Max pooling\n",
    "    - Dropout\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the model\n",
    "    model = Sequential()\n",
    "\n",
    "    if bias_init:\n",
    "        bias = bias_init\n",
    "    else:\n",
    "        bias='zeros'\n",
    "        \n",
    "    model.add(Conv2D(filters=6, kernel_size=(5, 5), strides=(1, 1), \n",
    "                     input_shape=(32, 32, 1), bias_initializer=bias)) # C1\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2))) # S2\n",
    "    model.add(Activation('relu'))\n",
    "    if dropout_cnt >= 1:\n",
    "        model.add(Dropout(dropout_val))\n",
    "    \n",
    "    model.add(Conv2D(filters=16, kernel_size=(5, 5), strides=(1, 1),\n",
    "                    bias_initializer=bias)) # C3\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2))) # S4\n",
    "    model.add(Activation('relu'))\n",
    "    if dropout_cnt >= 2:\n",
    "        model.add(Dropout(dropout_val))\n",
    "\n",
    "    model.add(Conv2D(filters=120, kernel_size=(5, 5), strides=(1, 1),\n",
    "                    bias_initializer=bias)) # C5\n",
    "    model.add(Activation('relu'))\n",
    "    if dropout_cnt >= 3:\n",
    "        model.add(Dropout(dropout_val))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(120)) # F6\n",
    "    model.add(Activation('relu'))\n",
    "    if dropout_cnt >= 4:\n",
    "        model.add(Dropout(dropout_val))\n",
    "    \n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    if verbose:\n",
    "        print(model.summary())\n",
    "    return model\n",
    "    \n",
    "lenet5 = lenet5_modern_model(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a grid search over dropout layer count and percentage\n",
    "\n",
    "Let's do a grid search to find out how many dropout layers gives the best performance, and what their percentage should be. We're restricting the state space by adding dropout layers from the first layer onwards, and using the same percentage on each layer.\n",
    "\n",
    "** This is going to take a long time to run!! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "results = dict()\n",
    "best_dropout = None\n",
    "min_error = 1.00\n",
    "RUNS = 3\n",
    "\n",
    "# Exhaustive grid search of dropout configs\n",
    "for dropout_cnt in range(1, 3):\n",
    "    for dropout_val in (0.1, 0.2, 0.3):\n",
    "        \n",
    "        print('\\nTesting {} runs with {} layer(s) of dropout, {} value .. '.format(RUNS, dropout_cnt, dropout_val))\n",
    "        errors = np.zeros((RUNS,))\n",
    "        for index in range(RUNS): # Run each combination multiple times\n",
    "            \n",
    "            model = lenet5_modern_model(dropout_cnt=dropout_cnt, dropout_val=dropout_val)\n",
    "            result = evaluate_model(model,\n",
    "                                    optimizer=SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True),\n",
    "                                    cv_split=None, verbose=False)\n",
    "\n",
    "            errors[index] = 1.0 - result['acc']\n",
    "        \n",
    "        result_key = (dropout_cnt, dropout_val)\n",
    "        mean, std = errors.mean(), errors.std()\n",
    "        \n",
    "        # Update the best settings based on worst case \n",
    "        if mean < min_error:\n",
    "            print(\"\\nUpdating best settings:\")\n",
    "            best_dropout = result_key\n",
    "            min_error = mean\n",
    "            \n",
    "        results[result_key] = {'mean': mean, 'std': std}\n",
    "        \n",
    "        print('dropout: {} @ {}, error: {:.4f} ({:.4f} std dev)'.format(*result_key, mean, std))\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Best dropout settings: {}, giving error of: {}'.format(best_dropout, min_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How much training data is enough ?!\n",
    "\n",
    "Now with the best dropout settings, let's train on increasingly more data, and see how the performance varies on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a new evaluation method where the data is passed in\n",
    "\n",
    "def evaluate_model(model, X_tr, y_tr, X_te, y_te, optimizer, batch=256, cv_split=None, verbose=False):\n",
    "    \"\"\"\n",
    "    Wrapper method to create, train and optionally CV, and check performance on test set\n",
    "    \"\"\"\n",
    "\n",
    "    if verbose:\n",
    "        print('\\nCompiling model')\n",
    "        model.summary()\n",
    "        \n",
    "    model.compile(optimizer=optimizer,\n",
    "                   loss='categorical_crossentropy', \n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "    if verbose:\n",
    "        print('\\nTraining model')\n",
    "    history = model.fit(X_tr, y_tr, validation_split=cv_split, \n",
    "                        epochs=20, batch_size=batch, verbose=1 if verbose else 0)\n",
    "\n",
    "    if verbose:\n",
    "        print('\\nEvaluating model')\n",
    "        \n",
    "    train_score = model.evaluate(X_tr, y_tr, batch_size=batch)\n",
    "    test_score = model.evaluate(X_te, y_te, batch_size=batch)\n",
    "\n",
    "    if verbose:\n",
    "        print('\\nTest results: Loss = {:.2f}, Error = {:.2f}'.format(100.0 * test_score[0], 100.0 * (1.0 - test_score[1])))\n",
    "    \n",
    "    results = {'model': model, 'history': history.history, \n",
    "               'train_loss': train_score[0], 'train_acc': train_score[1], 'train_err': 1.0 - train_score[1],\n",
    "               'test_loss': test_score[0], 'test_acc': test_score[1], 'test_err': 1.0 - test_score[1],\n",
    "              }\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "results = dict()\n",
    "\n",
    "best_err = 1.0\n",
    "\n",
    "for lr in range(1, 3):\n",
    "    for decay_p10 in range(5, 9):\n",
    "        for m in range(7, 11):\n",
    "            lr = 10 ** (-1 * lr) # 0.01 #  / (10 * (batch_p2 - 7))\n",
    "            decay = 10 ** (-1 * decay_p10) # 1e-6 # 7 * (10 * (batch_p2 - 7))\n",
    "            momentum = m * 0.1\n",
    "            batch_size = 256 #  ** batch_p2\n",
    "\n",
    "            print('Evaluating with lr: {}, decay: {}, batch size: {}'.format(lr, decay, batch_size))\n",
    "            start_time = time.time()\n",
    "            result = evaluate_model(lenet5_modern_model(dropout_cnt=2, dropout_val=0.1),\n",
    "                                    X_train, y_train, X_test, y_test,\n",
    "                                    optimizer=SGD(lr=0.01, decay=1e-6, momentum=0.8, nesterov=True),\n",
    "                                    batch=batch_size,\n",
    "                                    cv_split=None, verbose=False)\n",
    "            end_time = time.time()\n",
    "            time_diff = round((end_time - start_time) / 60.0, 1)\n",
    "            print('\\nCompleted in {} mins, test error: {:.2f}%'.format(time_diff, 100.0 * result['test_err']))\n",
    "#             results[batch_size] = {'result': result, time: time_diff}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "n_rows = range(5000, 65000, 5000)\n",
    "\n",
    "results = dict()\n",
    "\n",
    "for n in n_rows:\n",
    "    print('\\nValidating train and test set performance with {} training examples'.format(n))\n",
    "    X_train_sub, y_train_sub = stratified_subsample(X_train, y_train, n)\n",
    "    \n",
    "    model = lenet5_modern_model(dropout_cnt=2, dropout_val=0.1)\n",
    "    result = evaluate_model(model,\n",
    "                            X_train_sub, y_train_sub, X_test, y_test,\n",
    "                            optimizer=SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True),\n",
    "                            cv_split=None, verbose=False)\n",
    "\n",
    "    results[n] = result\n",
    "\n",
    "train_sub_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "train_sub_df.index.name=\"N\"\n",
    "train_sub_df = train_sub_df[['train_err', 'test_err']]\n",
    "train_sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sub_df.plot.line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image augmentation \n",
    "\n",
    "Plot the CV error and test error as a function of the training set size. Note the gap to motivate the image augmentation approach.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mis-classified examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling models\n",
    "\n",
    "Train multiple models, keep the ones with the least correlation and take mojority vote from them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read back the weights of the best performing network and visualize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
