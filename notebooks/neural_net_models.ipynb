{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network models\n",
    "\n",
    "This notebook picks up after the `simple_models` notebook. After trying a range of classification algorithms, we'll try out some of the neural network models in [1]. These include fully-connected models of varying layer sizes, and finally convolutional models including the famous LeNet-5. \n",
    "\n",
    "Along the way, we'll be using Keras which is a library sitting on top of Theano or Tensorflow. This allows easy construction, training and evaluation of neural nets. Before we get started, here's a recap of the `simple_models` notebook models.\n",
    "\n",
    "`[1]` - [Gradient-Based Learning Applied to Document Recognition](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf),  LeCun et al, Nov 1998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load in dependencies, may not use all of these\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pickle files\n",
    "\n",
    "The original data files are processed using the `convert_data.py` script, and written out to pickle files. We can load these in as numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pickle files ...\n"
     ]
    }
   ],
   "source": [
    "# Set up the file directory and names\n",
    "DIR = '../input/'\n",
    "X_TRAIN = DIR + 'train-images-idx3-ubyte.pkl'\n",
    "Y_TRAIN = DIR + 'train-labels-idx1-ubyte.pkl'\n",
    "X_TEST = DIR + 't10k-images-idx3-ubyte.pkl'\n",
    "Y_TEST = DIR + 't10k-labels-idx1-ubyte.pkl'\n",
    "\n",
    "def load_data():\n",
    "    '''Loads pickled ubyte files with MNIST data\n",
    "    INPUT: X_train_file, y_train_file - strings with training filenames\n",
    "           X_test_file, y_test_File - strings with test filenames\n",
    "    RETURNS: Tuple with (X_train, y_train, X_test, y_test)\n",
    "    '''\n",
    "    print('Loading pickle files ...')\n",
    "    try:\n",
    "        X_train = pickle.load( open( X_TRAIN, \"rb\" ) )\n",
    "        y_train = pickle.load( open( Y_TRAIN, \"rb\" ) )\n",
    "        X_test = pickle.load( open( X_TEST, \"rb\" ) )\n",
    "        y_test = pickle.load( open( Y_TEST, \"rb\" ) )\n",
    "    except:\n",
    "        print('Error loading pickle file')\n",
    "        return None\n",
    "        \n",
    "    return (X_train, y_train, X_test, y_test)\n",
    "\n",
    "X_train, y_train, X_test,  y_test = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "\n",
    "Before evaluating some models on the images, let's create some helper functions we can re-use later on. These deal with converting images to and from 1d and 2d versions, plotting images, resizing them, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train images shape (60000, 784), labels shape (60000, 1)\n",
      "Loaded test images shape (10000, 784), labels shape (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "def flatten_images(X):\n",
    "    ''' Converts images to 1-d vectors\n",
    "    INPUT: X - Input array of shape [n, w, h]\n",
    "    RETURNS: Numpy array of shape [n, w*h]\n",
    "    '''\n",
    "    n, w, h = X.shape\n",
    "    X_flat = X.reshape((n, w * h))\n",
    "    return X_flat\n",
    "\n",
    "def square_images(X, w=None, h=None):\n",
    "    '''Converts single-vector images into square images \n",
    "    INPUT: X - numpy array of images in single-vector form\n",
    "           w - width of images to convert to\n",
    "           h - height of images to convert to\n",
    "    RETURNS: Numpy array of shape [n, w, h]\n",
    "    '''\n",
    "    \n",
    "    assert X.shape[1] == w * h, \"Error - Can't square array of shape {} to {}\".format(X.shape, (w, h))\n",
    "    n = X.shape[0]\n",
    "    X_square = X.reshape((n, w, h))\n",
    "    return X_square\n",
    "\n",
    "\n",
    "N_TRAIN, W, H = X_train.shape\n",
    "N_TEST, w_test, h_test = X_test.shape\n",
    "\n",
    "# Flatten the images\n",
    "X_train = flatten_images(X_train)\n",
    "X_test = flatten_images(X_test)\n",
    "\n",
    "# Do some checks on the data\n",
    "assert N_TRAIN == 60000, 'Error - expected 60000 training images, got {}'.format(N_TRAIN)\n",
    "assert N_TEST == 10000, 'Error - expected 60000 training images, got {}'.format(N_TEST)\n",
    "assert W == w_test, 'Error - width mismatch. Train {}, Test {}'.format(w, w_test)\n",
    "assert H == h_test, 'Error - height mismatch. Train {}, Test {}'.format(h, h_test)\n",
    "\n",
    "assert np.array_equal(X_train, flatten_images(square_images(X_train, W, H)))\n",
    "assert X_train.shape[0] == y_train.shape[0]\n",
    "assert X_test.shape[0] == y_test.shape[0]\n",
    "\n",
    "print('Loaded train images shape {}, labels shape {}'.format(X_train.shape, y_train.shape))\n",
    "print('Loaded test images shape {}, labels shape {}'.format(X_test.shape, y_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "This section sets up global constants used in all models (to ensure a fair comparison). It also prepares the data by converting y values to one-hot, and normalizing X inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting y variables to one-hot encoding..\n",
      "Z-normalizing X data..\n",
      "Train images shape (60000, 784), labels shape (60000, 10)\n",
      "Test images shape (10000, 784), labels shape (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer, StandardScaler\n",
    "\n",
    "# Keras Common configuration\n",
    "SEED = 1234 # Fix the seed for repeatability\n",
    "N_JOBS=-2 # Leave 1 core free for UI updates\n",
    "VERBOSE=2 # 3 is the most verbose level\n",
    "NB_EPOCH = 20 # todo ! Check how many epochs in the paper\n",
    "BATCH = 256 # todo ! Check this in the paper too\n",
    "\n",
    "\n",
    "def stratified_subsample(X, y, num_rows):\n",
    "    '''Creates a stratified subsample of X and y\n",
    "    INPUT: X and y, numpy arrays\n",
    "    RETURNS: subset of X and y, maintaining class balances\n",
    "    '''\n",
    "    # Create a stratified, shuffled subset of the training data if needed\n",
    "    N = X.shape[0]\n",
    "    if num_rows < N:\n",
    "        print('Reducing size from {} to {} examples'.format(N, num_rows))\n",
    "        new_X, _, new_y, _ = train_test_split(X_train, y_train, \n",
    "                                              train_size=N, random_state=SEED)    \n",
    "\n",
    "def onehot_encode_y(y_train, y_test):\n",
    "    '''Convert y_train and y_test to a one-hot encoding version\n",
    "    INPUT: y_train - np.array of size (n_train,)\n",
    "           y_test - np.array of size (n_test,)\n",
    "    RETURNS: y_train - np.array of size (n_train, n_classes)\n",
    "             y_test - np.arary of size (n_test, n_classes)\n",
    "    '''    \n",
    "    print('Converting y variables to one-hot encoding..')\n",
    "    lbe = LabelBinarizer()\n",
    "    lbe.fit(y_train)\n",
    "    y_train = lbe.transform(y_train)\n",
    "    y_test = lbe.transform(y_test)\n",
    "    return y_train, y_test\n",
    "\n",
    "def z_norm_X(X_train, X_test):\n",
    "    '''Z-normalizes X_train and X_test with 0 mean and 1 std. dev.\n",
    "    INPUT: X_train - training set\n",
    "           X_test - test set\n",
    "    RETURNS: X_train - normalized version of same size\n",
    "             X_test - normalized version (using X_train parameters)\n",
    "    '''\n",
    "    print('Z-normalizing X data..')    \n",
    "    std = StandardScaler()\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_test = X_test.astype(np.float32)\n",
    "    std.fit(X_train)\n",
    "    X_train = std.transform(X_train)\n",
    "    X_test = std.transform(X_test)\n",
    "    return X_train, X_test\n",
    "    \n",
    "y_train, y_test = onehot_encode_y(y_train, y_test)\n",
    "X_train, X_test = z_norm_X(X_train, X_test)\n",
    "scores = dict()\n",
    "\n",
    "print('Train images shape {}, labels shape {}'.format(X_train.shape, y_train.shape))\n",
    "print('Test images shape {}, labels shape {}'.format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] C.5 - Baseline fully-connected models (original dataset)\n",
    "\n",
    "We'll first compare the performance of different fully-connected models on fully-connected networks of varying layers and size. These are all trained on the 28x28 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Create a dictionary to store model training and test info\n",
    "models = dict()\n",
    "\n",
    "class KerasFCModel(object):\n",
    "    \n",
    "    def __init__(self, model_name, model_type, input_dim, layers, \n",
    "                 activation, output_activation, verbose=None):\n",
    "        '''Initializes a new keras model'''\n",
    "        self.model_name = model_name\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        model = model_type\n",
    "        for idx, size in enumerate(layers):\n",
    "            if idx == 0:\n",
    "                if self.verbose == 2:\n",
    "                    print('Adding input dense layer, input dim {}, dim {}'.format(input_dim, size))\n",
    "                model.add(Dense(size, input_dim=input_dim))\n",
    "                model.add(Activation(activation))\n",
    "            elif idx == len(layers) - 1:\n",
    "                if self.verbose == 2:\n",
    "                    print('Adding dense layer {}, size {}, activation {}'.format(idx, size, activation))\n",
    "                model.add(Dense(size))\n",
    "                model.add(Activation(activation))\n",
    "            else:\n",
    "                if self.verbose == 2:\n",
    "                    print('Adding output layer {}, size {}, activation {}'.format(idx, size, output_activation))\n",
    "                model.add(Dense(size))\n",
    "                model.add(Activation(output_activation))\n",
    "                \n",
    "        if self.verbose == 1:\n",
    "            print('Model summary:\\n')\n",
    "            model.summary()\n",
    "        \n",
    "        self.model = model\n",
    "\n",
    "    def compile(self, loss, optimizer, metrics):\n",
    "        '''Compile the model'''\n",
    "        self.metrics = metrics\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer\n",
    "        # Need to flip error vs accuracy \n",
    "        metrics = ['acc' if metric is 'error' else metric for metric in metrics]\n",
    "        self.model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "          \n",
    "    def fit(self, X, y, nb_epoch, batch_size):\n",
    "        '''Fit model to training data'''\n",
    "        self.history = self.model.fit(X, y, nb_epoch=nb_epoch, batch_size=batch_size, verbose=self.verbose)\n",
    "\n",
    "    def evaluate(self, X, y, batch_size):\n",
    "        '''Evaluates the model on test data'''\n",
    "        output = self.model.evaluate(X, y, batch_size=batch_size)\n",
    "        results = dict()\n",
    "        for idx, metric in enumerate(self.model.metrics_names):\n",
    "            if metric == 'acc':\n",
    "                results['error'] = 1.0 - output[idx]\n",
    "            else:\n",
    "                results[metric] = output[idx]                \n",
    "        self.results = results\n",
    "    \n",
    "    def report(self):\n",
    "        '''Prints a recap of the model, how it was trained, and performance'''\n",
    "        report = dict()\n",
    "        if self.verbose == 2:\n",
    "            report['model_info'] = model.summary()\n",
    "            report['loss'] = self.loss\n",
    "            report['optimizer'] = self.optimizer.get_config()\n",
    "            report['metrics'] = self.metrics\n",
    "            report['history'] = self.history\n",
    "        report['results'] = self.results\n",
    "        return report\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Keras model...\n",
      "Compiling model...\n",
      "Training model...\n",
      "Evaluating model...\n",
      " 9472/10000 [===========================>..] - ETA: 0s\n",
      "fc-300-10 test results: 0.0265 error\n"
     ]
    }
   ],
   "source": [
    "# FC 300-10\n",
    "print('Creating Keras model...')\n",
    "model_a = KerasFCModel(model_name='fc-300-10', model_type=Sequential(), \n",
    "                       input_dim=784, layers=(300, 10), \n",
    "                       activation='sigmoid', output_activation='softmax',\n",
    "                       verbose=0)\n",
    "\n",
    "print('Compiling model...')\n",
    "model_a.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True),\n",
    "              metrics=['error'])\n",
    "\n",
    "print('Training model...')\n",
    "model_a.fit(X_train, y_train, nb_epoch=NB_EPOCH, batch_size=BATCH)\n",
    "\n",
    "print('Evaluating model...')\n",
    "model_a.evaluate(X_test, y_test, batch_size=BATCH)\n",
    "\n",
    "print('\\n{} test results: {:.4f} error'.format(model_a.model_name, model_a.report()['results']['error']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Keras model...\n",
      "Compiling model...\n",
      "Training model...\n",
      "Evaluating model...\n",
      " 8960/10000 [=========================>....] - ETA: 0s\n",
      "fc-1000-10 test results: 0.0266 error\n"
     ]
    }
   ],
   "source": [
    "# FC 1000-10\n",
    "print('Creating Keras model...')\n",
    "model_a = KerasFCModel(model_name='fc-1000-10', model_type=Sequential(), \n",
    "                       input_dim=784, layers=(1000, 10), \n",
    "                       activation='sigmoid', output_activation='softmax',\n",
    "                       verbose=0)\n",
    "\n",
    "print('Compiling model...')\n",
    "model_a.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True),\n",
    "              metrics=['error'])\n",
    "\n",
    "print('Training model...')\n",
    "model_a.fit(X_train, y_train, nb_epoch=NB_EPOCH, batch_size=BATCH)\n",
    "\n",
    "print('Evaluating model...')\n",
    "model_a.evaluate(X_test, y_test, batch_size=BATCH)\n",
    "\n",
    "print('\\n{} test results: {:.4f} error'.format(model_a.model_name, model_a.report()['results']['error']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Keras model...\n",
      "Compiling model...\n",
      "Training model...\n",
      "Evaluating model...\n",
      " 9472/10000 [===========================>..] - ETA: 0s\n",
      "fc-300-100-10 test results: 0.2449 error\n"
     ]
    }
   ],
   "source": [
    "# FC 300-100-10\n",
    "print('Creating Keras model...')\n",
    "model_a = KerasFCModel(model_name='fc-300-100-10', model_type=Sequential(), \n",
    "                       input_dim=784, layers=(300, 100, 10), \n",
    "                       activation='sigmoid', output_activation='softmax',\n",
    "                       verbose=0)\n",
    "\n",
    "print('Compiling model...')\n",
    "model_a.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True),\n",
    "              metrics=['error'])\n",
    "\n",
    "print('Training model...')\n",
    "model_a.fit(X_train, y_train, nb_epoch=NB_EPOCH, batch_size=BATCH)\n",
    "\n",
    "print('Evaluating model...')\n",
    "model_a.evaluate(X_test, y_test, batch_size=BATCH)\n",
    "\n",
    "print('\\n{} test results: {:.4f} error'.format(model_a.model_name, model_a.report()['results']['error']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Keras model...\n",
      "Compiling model...\n",
      "Training model...\n",
      "Evaluating model...\n",
      " 8448/10000 [========================>.....] - ETA: 0s\n",
      "fc-500-150-10 test results: 0.3693 error\n"
     ]
    }
   ],
   "source": [
    "# FC 500-150-10\n",
    "print('Creating Keras model...')\n",
    "model_a = KerasFCModel(model_name='fc-500-150-10', model_type=Sequential(), \n",
    "                       input_dim=784, layers=(500, 150, 10), \n",
    "                       activation='sigmoid', output_activation='softmax',\n",
    "                       verbose=0)\n",
    "\n",
    "print('Compiling model...')\n",
    "model_a.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True),\n",
    "              metrics=['error'])\n",
    "\n",
    "print('Training model...')\n",
    "model_a.fit(X_train, y_train, nb_epoch=NB_EPOCH, batch_size=BATCH)\n",
    "\n",
    "print('Evaluating model...')\n",
    "model_a.evaluate(X_test, y_test, batch_size=BATCH)\n",
    "\n",
    "print('\\n{} test results: {:.4f} error'.format(model_a.model_name, model_a.report()['results']['error']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing training image indexes [11427 43512 10406 21301 31898 23863 38534 13330 52723]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAckAAAHCCAYAAACE+DKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngCYJAIABTRIAAIP/Bw3eX6KpMAeOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9aac2421d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check a few training values at random as a sanity check\n",
    "def show_label_images(X, y, images=None):\n",
    "    '''Shows random images in a grid\n",
    "    INPUT: X - image data\n",
    "           y - class label\n",
    "           images - indexes of images to show. Randomly selected if None\n",
    "    RETURNS: Nothing.\n",
    "    '''\n",
    "    \n",
    "    num = 3\n",
    "    num_square = num ** 2\n",
    "    \n",
    "    if images is None:\n",
    "        images = np.random.randint(0, X.shape[0], num_square)\n",
    "        \n",
    "    print('Showing training image indexes {}'.format(images))\n",
    "\n",
    "    fig, axes = plt.subplots(num,num, figsize=(8,8))\n",
    "    for idx, val in enumerate(images):\n",
    "        r, c = divmod(idx, num)\n",
    "        ax = axes[r][c]\n",
    "        ax.imshow(X[images[idx]]) # , cmap=plt.cm.binary)\n",
    "        ax.annotate('Label: {}'.format(y[val]), xy=(1, 1))\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "\n",
    "show_label_images(square_images(X_train, 28, 28), y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image resizing functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from tqdm import *\n",
    "\n",
    "def resize_image(image, img_size, back_size, back_color):\n",
    "    '''Resizes the image to `new_size`, pastes in center of backgrond\n",
    "    INPUT: image = Input image\n",
    "           img_size = tuple of images new dimensions\n",
    "           back_size = tuple of new image background dimensions\n",
    "           back_color = color to fill background with\n",
    "    RETURNS: New image\n",
    "    '''\n",
    "\n",
    "    new_img = Image.new('L', back_size, (back_color,))\n",
    "    img = Image.fromarray(image)\n",
    "    img.thumbnail(img_size, Image.ANTIALIAS) \n",
    "\n",
    "    h_diff = int((back_size[0] - img_size[1]) / 2)\n",
    "    w_diff = int((back_size[1] - img_size[1]) / 2)\n",
    "\n",
    "    new_img.paste(img, (h_diff, w_diff))\n",
    "    return np.asarray(new_img)\n",
    "\n",
    "def resize_image_array(X, img_size, back_size, back_color, desc=None):\n",
    "    '''Resizes images held in a numpy array'''\n",
    "    X_out = np.zeros_like(X)\n",
    "    n_images = X.shape[0]\n",
    "    for idx in tqdm(range(n_images), desc=desc): # \"Resizing {} images\".format(n_images)):\n",
    "        X_out[idx] = resize_image(X[idx], img_size, back_size, 0)\n",
    "        \n",
    "    return X_out\n",
    "\n",
    "X_train_resize = resize_image_array(X_train_input, (20,20), (28,28), 0, 'Resizing training images')\n",
    "X_test_resize = resize_image_array(X_test_input, (20,20), (28,28), 0, 'Resizing training images')\n",
    "\n",
    "# Reshape the images so they're a single row in the numpy array\n",
    "X_train_resize = X_train_resize_float.reshape((n_train, w * h))\n",
    "X_test_resize = X_test_resize_float.reshape((n_test, w * h))\n",
    "\n",
    "\n",
    "print('Z-normalizing X data')\n",
    "std = StandardScaler()\n",
    "X_train_resize_float = X_train_resize.astype(np.float32)\n",
    "X_test_resize_float = X_test_resize.astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "std.fit(X_train_resize_float.astype(np.float32))\n",
    "X_train = std.transform(X_train_resize_float)\n",
    "X_test = std.transform(X_test_resize_float)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Model a - 28x28-300-10: 4.7% Error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(300, input_dim=784))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "print('Model summary:\\n')\n",
    "model.summary()\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('\\nTraining model\\n')\n",
    "model.fit(X_train, y_train,\n",
    "          nb_epoch=NB_EPOCH,\n",
    "          batch_size=BATCH,\n",
    "          verbose=2)\n",
    "\n",
    "print('\\nGenerating predictions on test set\\n')\n",
    "scores = model.evaluate(X_test, y_test, batch_size=BATCH)\n",
    "errors = [1.0 - score for score in scores]\n",
    "\n",
    "print('\\n\\nTest set training error {:.4f}, test error {:.4f}'.format(errors[0], errors[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
